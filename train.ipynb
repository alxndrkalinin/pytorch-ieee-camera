{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import random\n",
    "import argparse\n",
    "import glob\n",
    "import re\n",
    "import csv\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import jpeg4py as jpeg\n",
    "from conditional import conditional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "\n",
    "from utils import *\n",
    "from train_utils import *\n",
    "from custom_dataset import IEEECameraDataset, preprocess_image\n",
    "from custom_scheduler import ReduceLROnPlateau\n",
    "from custom_models import ResNet\n",
    "\n",
    "from multiprocessing import *\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='training.log', level=logging.INFO, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--max-epoch', type=int, default=200, help='Epoch to run')\n",
    "# parser.add_argument('-b', '--batch-size', type=int, default=16, help='Batch Size during training, e.g. -b 64')\n",
    "# parser.add_argument('-l', '--learning_rate', type=float, default=1e-4, help='Initial learning rate')\n",
    "# parser.add_argument('-m', '--model', help='load hdf5 model including weights (and continue training)')\n",
    "# #parser.add_argument('-w', '--weights', help='load hdf5 weights only (and continue training)')\n",
    "# #parser.add_argument('-do', '--dropout', type=float, default=0.3, help='Dropout rate for FC layers')\n",
    "# #parser.add_argument('-doc', '--dropout-classifier', type=float, default=0., help='Dropout rate for classifier')\n",
    "# parser.add_argument('-t', '--test', action='store_true', help='Test model and generate CSV submission file')\n",
    "# parser.add_argument('-tt', '--test-train', action='store_true', help='Test model on the training set')\n",
    "# parser.add_argument('-cs', '--crop-size', type=int, default=512, help='Crop size')\n",
    "# parser.add_argument('-w', '--workers', type=int, default=8, help='Num workers')\n",
    "# #parser.add_argument('-g', '--gpus', type=int, default=1, help='Number of GPUs to use')\n",
    "# #parser.add_argument('-p', '--pooling', type=str, default='avg', help='Type of pooling to use: avg|max|none')\n",
    "# #parser.add_argument('-nfc', '--no-fcs', action='store_true', help='Dont add any FC at the end, just a softmax')\n",
    "# #parser.add_argument('-kf', '--kernel-filter', action='store_true', help='Apply kernel filter')\n",
    "# #parser.add_argument('-lkf', '--learn-kernel-filter', action='store_true', help='Add a trainable kernel filter before classifier')\n",
    "# #parser.add_argument('-cm', '--classifier', type=str, default='ResNet50', help='Base classifier model to use')\n",
    "# parser.add_argument('-uiw', '--use-imagenet-weights', action='store_true', help='Use imagenet weights (transfer learning)')\n",
    "# parser.add_argument('-x', '--extra-dataset', action='store_true', help='Use dataset from https://www.kaggle.com/c/sp-society-camera-model-identification/discussion/47235')\n",
    "# #parser.add_argument('-v', '--verbose', action='store_true', help='Pring debug/verbose info')\n",
    "# parser.add_argument('-e', '--ensembling', type=str, default='arithmetic', help='Type of ensembling: arithmetic|geometric for TTA')\n",
    "# parser.add_argument('-tta', action='store_true', help='Enable test time augmentation')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "args_workers = 24\n",
    "args_crop_size = 512\n",
    "args_use_imagenet_weights = True\n",
    "args_model = False\n",
    "args_test = False\n",
    "args_test_train = False\n",
    "args_extra_dataset = True\n",
    "args_tta = True\n",
    "args_batch_size = 32\n",
    "args_learning_rate = 1e-4\n",
    "args_max_epoch = 200\n",
    "args_ensembling = 'arithmetic'\n",
    "\n",
    "num_workers = args_workers\n",
    "\n",
    "TRAIN_FOLDER       = 'train'\n",
    "EXTRA_TRAIN_FOLDER = 'flickr_images' #not used -> ./good_imgs_train.txt\n",
    "EXTRA_VAL_FOLDER   = 'val_images' #not used -> ./good_imgs_val.txt\n",
    "TEST_FOLDER        = '../../data/test/'\n",
    "\n",
    "CROP_SIZE = args_crop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment_name = 'resnet50_first'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "model = ResNet(len(CLASSES), pretrained=args_use_imagenet_weights)\n",
    "if cuda_is_available:\n",
    "    print('GPU on')\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "if args_model:\n",
    "    print(\"Loading model \" + args_model)\n",
    "    state_dict = torch.load(args_model)['state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # e.g. DenseNet201_do0.3_doc0.0_avg-epoch128-val_acc0.964744.hdf5\n",
    "    #args_classifier = match.group(2)\n",
    "    #CROP_SIZE = args_crop_size  = model.get_input_shape_at(0)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ids_train = [line.rstrip('\\n') for line in open('good_imgs_train.txt')]\n",
    "# ids_val   = [line.rstrip('\\n') for line in open('good_imgs_val.txt')]\n",
    "\n",
    "# def check_remove_broken(img_path):\n",
    "#     try:\n",
    "#         x = jpeg.JPEG(img_path).decode()\n",
    "#     except Exception:\n",
    "#         print('Decoding error:', img_path)\n",
    "#         os.remove(img_path)\n",
    "#     if x.ndim != 3:\n",
    "#         print('BROKEN: {}'.format(img_path))\n",
    "        \n",
    "# p = Pool(cpu_count() - 2)\n",
    "# p.map(check_remove_broken, tqdm(ids_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "ids = glob.glob(join(TRAIN_FOLDER, '*/*.jpg'))\n",
    "ids.sort()\n",
    "\n",
    "if not args_extra_dataset:\n",
    "    ids_train, ids_val = train_test_split(ids, test_size=0.1, random_state=SEED)\n",
    "else:\n",
    "    ids_train = [line.rstrip('\\n') for line in open('good_imgs_train.txt')]\n",
    "    ids_val   = [line.rstrip('\\n') for line in open('good_imgs_val.txt')]\n",
    "    #ids_train = ids\n",
    "    #ids_val   = [ ]\n",
    "\n",
    "    #extra_train_ids = [os.path.join(EXTRA_TRAIN_FOLDER,line.rstrip('\\n')) \\\n",
    "    #    for line in open(os.path.join(EXTRA_TRAIN_FOLDER, 'good_jpgs'))]\n",
    "    #low_quality =     [os.path.join(EXTRA_TRAIN_FOLDER,line.rstrip('\\n').split(' ')[0]) \\\n",
    "    #    for line in open(os.path.join(EXTRA_TRAIN_FOLDER, 'low-quality'))]\n",
    "    #extra_train_ids = [idx for idx in extra_train_ids if idx not in low_quality]\n",
    "    #extra_train_ids.sort()\n",
    "    #ids_train.extend(extra_train_ids)\n",
    "    #random.shuffle(ids_train)\n",
    "\n",
    "    #extra_val_ids = glob.glob(join(EXTRA_VAL_FOLDER,'*/*.jpg'))\n",
    "    #extra_val_ids.sort()\n",
    "    #ids_val.extend(extra_val_ids)\n",
    "\n",
    "    classes_val = [get_class(idx.split('/')[-2]) for idx in ids_val]\n",
    "    classes_val_count = np.bincount(classes_val)\n",
    "    max_classes_val_count = max(classes_val_count)\n",
    "\n",
    "    # Balance validation dataset by filling up classes with less items from training set (and removing those from there)\n",
    "    for class_idx in range(N_CLASSES):\n",
    "        idx_to_transfer = [idx for idx in ids_train \\\n",
    "            if get_class(idx.split('/')[-2]) == class_idx][:max_classes_val_count-classes_val_count[class_idx]]\n",
    "\n",
    "        ids_train = list(set(ids_train).difference(set(idx_to_transfer)))\n",
    "\n",
    "        ids_val.extend(idx_to_transfer)\n",
    "\n",
    "    #random.shuffle(ids_val)\n",
    "\n",
    "print(\"Training set distribution:\")\n",
    "print_distribution(ids_train)\n",
    "\n",
    "print(\"Validation set distribution:\")\n",
    "print_distribution(ids_val)\n",
    "\n",
    "classes_train = [get_class(idx.split('/')[-2]) for idx in ids_train]\n",
    "comp_class_weight = class_weight.compute_class_weight('balanced', np.unique(classes_train), classes_train)\n",
    "classes_val = [get_class(idx.split('/')[-2]) for idx in ids_val]\n",
    "\n",
    "weights = [comp_class_weight[i_class] for i_class in classes_train]\n",
    "weights = torch.DoubleTensor(weights)\n",
    "train_sampler = sampler.WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "weights = [comp_class_weight[i_class] for i_class in classes_val]\n",
    "weights = torch.DoubleTensor(weights)\n",
    "val_sampler = sampler.WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "train_dataset = IEEECameraDataset(ids_train, crop_size=CROP_SIZE, training=True)\n",
    "val_dataset = IEEECameraDataset(ids_val, crop_size=CROP_SIZE, training=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=args_batch_size, sampler=train_sampler, num_workers=num_workers, pin_memory=True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=args_batch_size // 4, sampler=val_sampler, num_workers=num_workers, pin_memory=True, collate_fn=default_collate_unsqueeze)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=args_learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=10, min_lr=1e-9, epsilon=1e-5, verbose=1, mode='min')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print('Starting training...')\n",
    "\n",
    "best_val_loss = None\n",
    "train_and_validate(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    criterion,\n",
    "    args_max_epoch,\n",
    "    1,\n",
    "    best_val_loss,\n",
    "    experiment_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i_batch, sample in enumerate(train_loader):\n",
    "#     print(i_batch, sample['image'].size())\n",
    "#     print(i_batch, sample['image'].mean())\n",
    "# #     for i in xrange(sample['image'].size()[0]):\n",
    "# #         img = sample['image'][i,0,:,:].numpy()\n",
    "# #         plt.figure()\n",
    "# #         plt.imshow(img, cmap=plt.cm.gray)\n",
    "#     if i_batch == 100:\n",
    "#         break\n",
    "\n",
    "# i = 0\n",
    "# for ib, b in enumerate(train_loader):\n",
    "# #     print(i)\n",
    "#     print(i*16)\n",
    "#     print(len(b))\n",
    "#     i+=1\n",
    "#     if i>150:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_test = True\n",
    "args_model='resnet50_first_14_0.45544702479.pth'\n",
    "\n",
    "model = ResNet(len(CLASSES), pretrained=args_use_imagenet_weights)\n",
    "if cuda_is_available:\n",
    "    print('GPU on')\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "if args_model:\n",
    "    print(\"Loading model \" + args_model)\n",
    "    state_dict = torch.load('models/'+args_model)['state_dict']\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "if args_test:\n",
    "    ids = glob.glob(join(TEST_FOLDER, '*.tif'))\n",
    "    print(len(ids))\n",
    "elif args_test_train:\n",
    "    ids = glob.glob(join(TRAIN_FOLDER, '*/*.jpg'))\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "ids.sort()\n",
    "\n",
    "match = re.search(r'([^/]*)\\.pth', args_model)\n",
    "model_name = match.group(1) + ('_tta_' + args_ensembling if args_tta else '')\n",
    "csv_name   = 'submission_' + model_name + '.csv'\n",
    "\n",
    "model.eval()\n",
    "with conditional(args_test, open(csv_name, 'w')) as csvfile:\n",
    "\n",
    "    if args_test:\n",
    "        csv_writer = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(['fname', 'camera'])\n",
    "        classes = []\n",
    "    else:\n",
    "        correct_predictions = 0\n",
    "\n",
    "    for i, idx in enumerate(tqdm(ids)):\n",
    "\n",
    "        img = np.array(Image.open(idx))\n",
    "\n",
    "        if args_test_train:\n",
    "            img = get_crop(img, 512*2, random_crop=False)\n",
    "\n",
    "        original_img = img\n",
    "\n",
    "        original_manipulated = np.float32([1. if idx.find('manip') != -1 else 0.])\n",
    "\n",
    "        sx = img.shape[1] // CROP_SIZE\n",
    "        sy = img.shape[0] // CROP_SIZE\n",
    "\n",
    "        if args_test and args_tta:\n",
    "            transforms = [[], ['orientation']]\n",
    "        elif args_test_train:\n",
    "            transforms = [[], ['orientation'], ['manipulation'], ['manipulation', 'orientation']]\n",
    "        else:\n",
    "            transforms = [[]]\n",
    "\n",
    "        img_batch         = np.zeros((len(transforms)* sx * sy, CROP_SIZE, CROP_SIZE, 3), dtype=np.float32)\n",
    "        manipulated_batch = np.zeros((len(transforms)* sx * sy, 1),  dtype=np.float32)\n",
    "\n",
    "        i = 0\n",
    "        for transform in transforms:\n",
    "            img = np.copy(original_img)\n",
    "            manipulated = np.copy(original_manipulated)\n",
    "\n",
    "            if 'orientation' in transform:\n",
    "                img = np.rot90(img, 1, (0,1))\n",
    "            if 'manipulation' in transform and not original_manipulated:\n",
    "                img = random_manipulation(img)\n",
    "                manipulated = np.float32([1.])\n",
    "\n",
    "            if args_test_train:\n",
    "                img = get_crop(img, 512, random_crop=False)\n",
    "\n",
    "            sx = img.shape[1] // CROP_SIZE\n",
    "            sy = img.shape[0] // CROP_SIZE\n",
    "\n",
    "            for x in range(sx):\n",
    "                for y in range(sy):\n",
    "                    _img = np.copy(img[y*CROP_SIZE:(y+1)*CROP_SIZE, x*CROP_SIZE:(x+1)*CROP_SIZE])\n",
    "                    img_batch[i]         = preprocess_image(_img)\n",
    "                    manipulated_batch[i] = manipulated\n",
    "                    i += 1\n",
    "\n",
    "        img_batch, manipulated_batch = variable(torch.from_numpy(img_batch)), variable(torch.from_numpy(manipulated_batch))\n",
    "        prediction = model(img_batch, manipulated_batch).data.cpu().numpy()\n",
    "        if prediction.shape[0] != 1: # TTA\n",
    "            if args_ensembling == 'geometric':\n",
    "                predictions = np.log(prediction + K.epsilon()) # avoid numerical instability log(0)\n",
    "            prediction = np.sum(prediction, axis=0)\n",
    "\n",
    "        prediction_class_idx = np.argmax(prediction)\n",
    "\n",
    "        if args_test_train:\n",
    "            class_idx = get_class(idx.split('/')[-2])\n",
    "            if class_idx == prediction_class_idx:\n",
    "                correct_predictions += 1\n",
    "\n",
    "        if args_test:\n",
    "            csv_writer.writerow([idx.split('/')[-1], CLASSES[prediction_class_idx]])\n",
    "            classes.append(prediction_class_idx)\n",
    "\n",
    "    if args_test_train:\n",
    "        print(\"Accuracy: \" + str(correct_predictions / (len(transforms) * i)))\n",
    "\n",
    "    if args_test:\n",
    "        print(\"Test set predictions distribution:\")\n",
    "        print_distribution(None, classes=classes)\n",
    "        print(\"Now you are ready to:\")\n",
    "        print(\"kg submit {}\".format(csv_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
