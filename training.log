2018-02-07 21:06:41,361 Epoch: 1
2018-02-07 21:34:55,882 Epoch: 1
2018-02-07 21:35:04,824 Step: 0, train_loss: 2.33486890793
2018-02-07 23:00:51,140 Epoch: 1
2018-02-07 23:01:39,180 Epoch: 1
2018-02-07 23:01:46,720 Step: 0, train_loss: 2.2956802845
2018-02-07 23:12:17,811 Epoch: 1
2018-02-07 23:24:34,900 Epoch: 1
2018-02-07 23:24:38,794 Step: 0, train_loss: 2.30281996727
2018-02-07 23:39:37,494 Epoch: 1
2018-02-07 23:43:03,429 Epoch: 1
2018-02-07 23:43:07,695 Step: 0, train_loss: 2.20455551147
2018-02-07 23:44:08,854 Epoch: 1
2018-02-07 23:44:12,947 Step: 0, train_loss: 2.21951746941
2018-02-08 00:24:38,858 Epoch: 1
2018-02-08 00:24:42,410 Step: 0, train_loss: 2.27969932556
2018-02-08 00:26:28,981 Epoch: 1
2018-02-08 00:26:37,975 Step: 0, train_loss: 2.3613345623
2018-02-08 00:29:45,389 Epoch: 1
2018-02-08 00:29:53,707 Step: 0, train_loss: 2.28750014305
2018-02-08 00:33:44,216 Epoch: 1
2018-02-08 00:33:52,852 Step: 0, train_loss: 2.25673556328
2018-02-08 00:55:50,754 Epoch: 1
2018-02-08 00:55:54,918 Step: 0, train_loss: 2.40129089355
2018-02-08 00:57:27,879 Epoch: 1
2018-02-08 01:00:44,077 Epoch: 1
2018-02-08 01:00:52,816 Step: 0, train_loss: 2.27870798111
2018-02-08 01:02:48,292 Epoch: 1
2018-02-08 01:02:52,437 Step: 0, train_loss: 2.40108656883
2018-02-08 01:04:36,644 Epoch: 1
2018-02-08 01:04:40,301 Step: 0, train_loss: 2.32126259804
2018-02-08 01:06:09,385 Epoch: 1
2018-02-08 01:06:13,074 Step: 0, train_loss: 2.30203771591
2018-02-08 01:07:06,746 Epoch: 1
2018-02-08 01:07:10,554 Step: 0, train_loss: 2.15637326241
2018-02-08 01:08:12,882 Epoch: 1
2018-02-08 01:08:16,994 Step: 0, train_loss: 2.29373407364
2018-02-08 01:08:52,110 Epoch: 1
2018-02-08 01:08:55,556 Step: 0, train_loss: 2.27674770355
2018-02-08 01:10:19,555 Epoch: 1
2018-02-08 01:10:23,511 Step: 0, train_loss: 2.30683732033
2018-02-08 01:11:16,438 Epoch: 1
2018-02-08 01:11:21,015 Step: 0, train_loss: 2.060785532
2018-02-08 01:38:50,893 Epoch: 1
2018-02-08 01:38:59,844 Step: 0, train_loss: 2.35110068321
2018-02-08 01:39:19,717 Step: 50, train_loss: 2.20863187551
2018-02-08 02:26:47,884 Epoch: 1
2018-02-08 02:26:58,551 Step: 0, train_loss: 2.32083153725
2018-02-08 02:27:17,448 Step: 50, train_loss: 2.20049412966
2018-02-08 03:45:31,157 Epoch: 1
2018-02-08 03:45:40,983 Step: 0, train_loss: 2.3694164753
2018-02-08 03:45:59,797 Step: 50, train_loss: 2.2277984786
2018-02-08 03:46:18,502 Step: 100, train_loss: 1.9799680686
2018-02-08 03:46:37,422 Step: 150, train_loss: 1.76305539131
2018-02-08 03:46:56,332 Step: 200, train_loss: 1.65007452965
2018-02-08 03:47:15,507 Step: 250, train_loss: 1.5555168891
2018-02-08 03:47:34,622 Step: 300, train_loss: 1.45102950931
2018-02-08 03:47:53,659 Step: 350, train_loss: 1.35750624895
2018-02-08 03:48:12,826 Step: 400, train_loss: 1.21916534305
2018-02-08 03:48:25,199 train_loss: 1.6242829906
2018-02-08 03:54:07,926 Epoch: 1
2018-02-08 03:54:16,192 Step: 0, train_loss: 2.34165167809
2018-02-08 03:54:51,834 Step: 50, train_loss: 2.02439347267
2018-02-08 03:55:26,512 Step: 100, train_loss: 1.47578502893
2018-02-08 03:56:01,352 Step: 150, train_loss: 1.16872647762
2018-02-08 03:56:36,389 Step: 200, train_loss: 1.02246447444
2018-02-08 03:56:47,302 train_loss: 1.39754365721
2018-02-08 04:02:26,847 Epoch: 1
2018-02-08 04:02:36,200 Step: 0, train_loss: 0.777809858322
2018-02-08 04:03:10,889 Step: 50, train_loss: 0.972992334962
2018-02-08 04:03:45,911 Step: 100, train_loss: 0.805223092437
2018-02-08 04:04:20,982 Step: 150, train_loss: 0.778798335791
2018-02-08 04:04:55,892 Step: 200, train_loss: 0.724981023073
2018-02-08 04:05:06,776 train_loss: 0.811716925713
2018-02-08 04:06:18,188 Epoch: 1
2018-02-08 04:06:34,735 Step: 0, train_loss: 2.30215978622
2018-02-08 04:07:09,549 Step: 50, train_loss: 2.04471847057
2018-02-08 04:07:44,456 Step: 100, train_loss: 1.47313649178
2018-02-08 04:08:19,387 Step: 150, train_loss: 1.16708170533
2018-02-08 04:08:54,369 Step: 200, train_loss: 1.01645502448
2018-02-08 04:09:05,292 train_loss: 1.39519989491
2018-02-08 04:09:21,436 valid_loss: 1.26211487005, valid_acc: 0.609504132231
2018-02-08 04:09:21,801 Epoch: 2
2018-02-08 04:09:29,664 Step: 0, train_loss: 1.08536553383
2018-02-08 04:10:04,776 Step: 50, train_loss: 0.968277381659
2018-02-08 04:10:39,666 Step: 100, train_loss: 0.896211990714
2018-02-08 04:11:14,922 Step: 150, train_loss: 0.758254215121
2018-02-08 04:11:50,005 Step: 200, train_loss: 0.743683431745
2018-02-08 04:12:00,966 train_loss: 0.824684395905
2018-02-08 04:12:17,504 valid_loss: 1.16182803114, valid_acc: 0.652645861601
2018-02-08 04:12:17,889 Epoch: 3
2018-02-08 04:12:27,621 Step: 0, train_loss: 0.487453311682
2018-02-08 04:13:02,703 Step: 50, train_loss: 0.683313227296
2018-02-08 04:13:37,760 Step: 100, train_loss: 0.67584015727
2018-02-08 04:14:13,093 Step: 150, train_loss: 0.715312760174
2018-02-08 04:14:48,134 Step: 200, train_loss: 0.608460278511
2018-02-08 04:14:59,034 train_loss: 0.667014092138
2018-02-08 04:15:15,577 valid_loss: 0.727727080882, valid_acc: 0.790884718499
2018-02-08 04:15:15,942 Epoch: 4
2018-02-08 04:15:24,230 Step: 0, train_loss: 0.605190038681
2018-02-08 04:15:59,377 Step: 50, train_loss: 0.580426536798
2018-02-08 04:16:34,395 Step: 100, train_loss: 0.581649173796
2018-02-08 04:17:09,520 Step: 150, train_loss: 0.532303079963
2018-02-08 04:17:44,507 Step: 200, train_loss: 0.560679930449
2018-02-08 04:17:55,547 train_loss: 0.565681064115
2018-02-08 04:18:11,189 valid_loss: 0.667468270939, valid_acc: 0.807371349096
2018-02-08 04:18:11,501 Epoch: 5
2018-02-08 04:18:18,907 Step: 0, train_loss: 0.374610245228
2018-02-08 04:18:54,984 Step: 50, train_loss: 0.551216273606
2018-02-08 04:19:30,159 Step: 100, train_loss: 0.523206265271
2018-02-08 04:20:05,295 Step: 150, train_loss: 0.515515895188
2018-02-08 04:20:40,268 Step: 200, train_loss: 0.512473160028
2018-02-08 04:20:51,217 train_loss: 0.524245270867
2018-02-08 04:21:06,649 valid_loss: 0.547314418294, valid_acc: 0.845070422535
2018-02-08 04:21:06,971 Epoch: 6
2018-02-08 04:21:16,113 Step: 0, train_loss: 0.380979597569
2018-02-08 04:21:51,200 Step: 50, train_loss: 0.476342315972
2018-02-08 04:22:26,282 Step: 100, train_loss: 0.421452610195
2018-02-08 04:23:01,500 Step: 150, train_loss: 0.46883797437
2018-02-08 04:23:36,471 Step: 200, train_loss: 0.445282199681
2018-02-08 04:23:47,470 train_loss: 0.457471226767
2018-02-08 04:24:03,416 valid_loss: 0.70024505121, valid_acc: 0.793103448276
2018-02-08 04:24:03,424 Epoch: 7
2018-02-08 04:24:13,589 Step: 0, train_loss: 0.541870117188
2018-02-08 04:24:48,628 Step: 50, train_loss: 0.397536864579
2018-02-08 04:25:23,742 Step: 100, train_loss: 0.424656846225
2018-02-08 04:25:58,870 Step: 150, train_loss: 0.430327679217
2018-02-08 04:26:33,930 Step: 200, train_loss: 0.468246430457
2018-02-08 04:26:44,948 train_loss: 0.429305305335
2018-02-08 04:27:01,192 valid_loss: 0.535669557781, valid_acc: 0.841192787795
2018-02-08 04:27:01,517 Epoch: 8
2018-02-08 04:27:09,956 Step: 0, train_loss: 0.23878736794
2018-02-08 04:27:45,125 Step: 50, train_loss: 0.359299157262
2018-02-08 04:28:20,335 Step: 100, train_loss: 0.400144893229
2018-02-08 04:28:55,501 Step: 150, train_loss: 0.403094682395
2018-02-08 04:29:30,594 Step: 200, train_loss: 0.434259404242
2018-02-08 04:29:41,591 train_loss: 0.401465955006
2018-02-08 04:29:58,421 valid_loss: 0.80164333585, valid_acc: 0.816216216216
2018-02-08 04:29:58,431 Epoch: 9
2018-02-08 04:30:06,944 Step: 0, train_loss: 0.196097373962
2018-02-08 04:30:42,156 Step: 50, train_loss: 0.39059638083
2018-02-08 04:31:17,299 Step: 100, train_loss: 0.433874644339
2018-02-08 04:31:52,316 Step: 150, train_loss: 0.376272634417
2018-02-08 04:32:27,344 Step: 200, train_loss: 0.359117058069
2018-02-08 04:32:38,328 train_loss: 0.3878701893
2018-02-08 04:32:55,067 valid_loss: 0.524718629491, valid_acc: 0.863699582754
2018-02-08 04:32:55,399 Epoch: 10
2018-02-08 04:33:03,063 Step: 0, train_loss: 0.805302381516
2018-02-08 04:33:38,174 Step: 50, train_loss: 0.374352276921
2018-02-08 04:34:13,336 Step: 100, train_loss: 0.349159005284
2018-02-08 04:34:48,606 Step: 150, train_loss: 0.360092816651
2018-02-08 04:35:23,492 Step: 200, train_loss: 0.333631967008
2018-02-08 04:35:34,502 train_loss: 0.365036613827
2018-02-08 04:35:50,824 valid_loss: 0.56917941443, valid_acc: 0.843665768194
2018-02-08 04:35:50,831 Epoch: 11
2018-02-08 04:36:00,569 Step: 0, train_loss: 0.286375969648
2018-02-08 04:36:35,557 Step: 50, train_loss: 0.372356684208
2018-02-08 04:37:10,699 Step: 100, train_loss: 0.343344117403
2018-02-08 04:37:45,752 Step: 150, train_loss: 0.324563706964
2018-02-08 04:38:20,719 Step: 200, train_loss: 0.359222447425
2018-02-08 04:38:31,688 train_loss: 0.347156213382
2018-02-08 04:38:47,880 valid_loss: 0.774933361573, valid_acc: 0.789804469274
2018-02-08 04:38:47,889 Epoch: 12
2018-02-08 04:38:57,068 Step: 0, train_loss: 0.550069093704
2018-02-08 04:39:32,248 Step: 50, train_loss: 0.348455982655
2018-02-08 04:40:07,534 Step: 100, train_loss: 0.338078434467
2018-02-08 04:40:42,730 Step: 150, train_loss: 0.341653991193
2018-02-08 04:41:17,658 Step: 200, train_loss: 0.317563212365
2018-02-08 04:41:28,658 train_loss: 0.332075687786
2018-02-08 04:41:45,068 valid_loss: 0.481929688187, valid_acc: 0.865620736698
2018-02-08 04:41:45,376 Epoch: 13
2018-02-08 04:41:53,177 Step: 0, train_loss: 0.252385735512
2018-02-08 04:42:29,159 Step: 50, train_loss: 0.294740700871
2018-02-08 04:43:04,279 Step: 100, train_loss: 0.280369285643
2018-02-08 04:43:39,385 Step: 150, train_loss: 0.315155576169
2018-02-08 04:44:14,490 Step: 200, train_loss: 0.358733502775
2018-02-08 04:44:25,419 train_loss: 0.314360413683
2018-02-08 04:44:41,185 valid_loss: 0.476932049155, valid_acc: 0.847765363128
2018-02-08 04:44:41,531 Epoch: 14
2018-02-08 04:44:48,494 Step: 0, train_loss: 0.163559734821
2018-02-08 04:45:24,189 Step: 50, train_loss: 0.304309466928
2018-02-08 04:45:59,411 Step: 100, train_loss: 0.288374848366
2018-02-08 04:46:34,509 Step: 150, train_loss: 0.333516679257
2018-02-08 04:47:09,443 Step: 200, train_loss: 0.277021931708
2018-02-08 04:47:20,450 train_loss: 0.305619719975
2018-02-08 04:47:36,180 valid_loss: 0.45544702479, valid_acc: 0.879642365887
2018-02-08 04:47:36,522 Epoch: 15
2018-02-08 04:47:44,911 Step: 0, train_loss: 0.13674902916
2018-02-08 04:48:20,286 Step: 50, train_loss: 0.32484517619
2018-02-08 04:48:55,503 Step: 100, train_loss: 0.240715833306
2018-02-08 04:49:30,670 Step: 150, train_loss: 0.345946294665
2018-02-08 04:50:05,678 Step: 200, train_loss: 0.279058448672
2018-02-08 04:50:16,664 train_loss: 0.298303426342
2018-02-08 04:50:33,285 valid_loss: 0.495213992312, valid_acc: 0.876033057851
2018-02-08 04:50:33,292 Epoch: 16
2018-02-08 04:50:43,175 Step: 0, train_loss: 0.334251612425
2018-02-08 04:51:18,189 Step: 50, train_loss: 0.263768814802
2018-02-08 04:51:53,404 Step: 100, train_loss: 0.313658336699
2018-02-08 04:52:28,520 Step: 150, train_loss: 0.298028243035
2018-02-08 04:53:03,486 Step: 200, train_loss: 0.310087096542
2018-02-08 04:53:14,466 train_loss: 0.29410328074
2018-02-08 04:53:30,505 valid_loss: 0.457937070789, valid_acc: 0.87550744249
2018-02-08 04:53:30,512 Epoch: 17
2018-02-08 04:53:38,989 Step: 0, train_loss: 0.33502432704
2018-02-08 04:54:14,130 Step: 50, train_loss: 0.268696118891
2018-02-08 04:54:49,341 Step: 100, train_loss: 0.24640393883
2018-02-08 04:55:24,488 Step: 150, train_loss: 0.282501136512
2018-02-08 04:55:59,572 Step: 200, train_loss: 0.323697077185
2018-02-08 04:56:10,571 train_loss: 0.28476580538
2018-02-08 04:56:26,546 valid_loss: 0.322067435916, valid_acc: 0.901960784314
2018-02-08 04:56:26,915 Epoch: 18
2018-02-08 04:56:34,407 Step: 0, train_loss: 0.365898668766
2018-02-08 04:57:10,376 Step: 50, train_loss: 0.243204709888
2018-02-08 06:06:27,356 Epoch: 1
2018-02-08 06:08:21,744 Epoch: 1
2018-02-08 06:10:58,223 Epoch: 1
2018-02-08 06:23:13,189 Epoch: 1
2018-02-08 06:27:40,805 Epoch: 1
2018-02-08 06:28:38,764 Epoch: 1
2018-02-08 06:29:42,115 Epoch: 1
2018-02-08 06:32:05,654 Epoch: 1
2018-02-08 06:33:54,833 Epoch: 1
2018-02-08 06:35:33,792 Epoch: 1
2018-02-08 06:35:38,659 Step: 0, train_loss: 2.31271076202
2018-02-08 06:35:57,878 Step: 50, train_loss: 2.25676062822
2018-02-08 06:36:17,189 Step: 100, train_loss: 2.04874107361
2018-02-08 06:36:36,551 Step: 150, train_loss: 1.88032006979
2018-02-08 06:36:55,921 Step: 200, train_loss: 1.74102248669
2018-02-08 06:37:15,354 Step: 250, train_loss: 1.57171706676
2018-02-08 06:37:34,801 Step: 300, train_loss: 1.42825942755
2018-02-08 06:37:54,201 Step: 350, train_loss: 1.43396679521
2018-02-08 06:38:13,570 Step: 400, train_loss: 1.46616733432
2018-02-08 06:38:32,942 Step: 450, train_loss: 1.3469126904
2018-02-08 06:38:52,371 Step: 500, train_loss: 1.26744691133
2018-02-08 06:39:11,853 Step: 550, train_loss: 1.25258001089
2018-02-08 06:39:31,332 Step: 600, train_loss: 1.22203432322
2018-02-08 06:39:50,774 Step: 650, train_loss: 1.11848248184
2018-02-08 06:40:10,273 Step: 700, train_loss: 1.06991569161
2018-02-08 06:40:29,685 Step: 750, train_loss: 1.10049665272
2018-02-08 06:40:49,208 Step: 800, train_loss: 0.971714942455
2018-02-08 06:41:08,534 Step: 850, train_loss: 0.847298724651
2018-02-08 06:41:14,631 train_loss: 1.40978230971
2018-02-08 06:41:38,985 valid_loss: 0.849830643885, valid_acc: 0.730717185386
2018-02-08 06:41:39,430 Epoch: 2
2018-02-08 06:41:42,713 Step: 0, train_loss: 0.806170701981
2018-02-08 06:42:02,228 Step: 50, train_loss: 1.0548685503
2018-02-08 06:42:21,731 Step: 100, train_loss: 0.964927020073
2018-02-08 06:42:41,174 Step: 150, train_loss: 0.990386804342
2018-02-08 06:46:42,745 Epoch: 1
2018-02-08 06:46:57,435 Step: 0, train_loss: 2.28059053421
2018-02-08 06:47:36,521 Step: 50, train_loss: 2.19810493946
2018-02-08 06:48:15,525 Step: 100, train_loss: 1.83483487606
2018-02-08 06:48:54,598 Step: 150, train_loss: 1.51969740391
2018-02-08 06:49:33,684 Step: 200, train_loss: 1.31870098829
2018-02-08 06:50:12,809 Step: 250, train_loss: 1.24865574241
2018-02-08 06:50:51,647 Step: 300, train_loss: 1.06386986613
2018-02-08 06:51:30,751 Step: 350, train_loss: 1.08772423387
2018-02-08 06:51:57,840 train_loss: 1.42791003931
2018-02-08 06:52:34,795 valid_loss: 0.961100642756, valid_acc: 0.719749652295
2018-02-08 06:52:35,223 Epoch: 2
2018-02-08 06:52:43,071 Step: 0, train_loss: 1.11211490631
2018-02-08 06:53:22,159 Step: 50, train_loss: 0.859526391625
2018-02-08 06:54:01,108 Step: 100, train_loss: 0.825671378374
2018-02-08 06:54:39,726 Step: 150, train_loss: 0.756042047143
2018-02-08 06:55:18,737 Step: 200, train_loss: 0.830646370053
2018-02-08 06:55:57,969 Step: 250, train_loss: 0.776709423661
2018-02-08 06:56:37,284 Step: 300, train_loss: 0.74910466373
2018-02-08 06:57:16,555 Step: 350, train_loss: 0.692155454159
2018-02-08 06:57:43,654 train_loss: 0.782373164756
2018-02-08 06:58:21,025 valid_loss: 0.615030290792, valid_acc: 0.837001375516
2018-02-08 06:58:21,438 Epoch: 3
2018-02-08 06:58:27,776 Step: 0, train_loss: 0.510388076305
2018-02-08 06:59:07,208 Step: 50, train_loss: 0.680197889805
2018-02-08 06:59:46,446 Step: 100, train_loss: 0.630369685292
2018-02-08 07:00:25,779 Step: 150, train_loss: 0.696152175665
2018-02-08 07:01:05,090 Step: 200, train_loss: 0.558525295854
2018-02-08 07:01:44,150 Step: 250, train_loss: 0.667955070436
2018-02-08 07:02:23,912 Step: 300, train_loss: 0.664055451751
2018-02-08 07:03:03,009 Step: 350, train_loss: 0.619899452329
2018-02-08 07:03:30,217 train_loss: 0.652524473792
2018-02-08 07:04:07,655 valid_loss: 0.571950700675, valid_acc: 0.839945280438
2018-02-08 07:04:08,100 Epoch: 4
2018-02-08 07:04:14,373 Step: 0, train_loss: 0.496886581182
2018-02-08 07:04:54,348 Step: 50, train_loss: 0.598233801723
2018-02-08 07:05:33,706 Step: 100, train_loss: 0.578384543955
2018-02-08 07:06:12,963 Step: 150, train_loss: 0.551885240823
2018-02-08 07:06:52,046 Step: 200, train_loss: 0.604234428704
2018-02-08 07:07:31,397 Step: 250, train_loss: 0.571441409886
2018-02-08 07:08:10,453 Step: 300, train_loss: 0.567073678374
2018-02-08 07:08:49,511 Step: 350, train_loss: 0.519611888528
2018-02-08 07:09:16,469 train_loss: 0.567279972348
2018-02-08 07:09:54,097 valid_loss: 0.456371141615, valid_acc: 0.871266002845
2018-02-08 07:09:54,512 Epoch: 5
2018-02-08 07:10:01,515 Step: 0, train_loss: 0.356780946255
2018-02-08 07:10:41,159 Step: 50, train_loss: 0.564758295417
2018-02-08 07:11:20,276 Step: 100, train_loss: 0.458764147162
2018-02-08 07:11:59,197 Step: 150, train_loss: 0.453656417876
2018-02-08 07:12:38,643 Step: 200, train_loss: 0.514781470001
2018-02-08 07:13:18,040 Step: 250, train_loss: 0.436134480238
2018-02-08 07:13:57,548 Step: 300, train_loss: 0.530162341148
2018-02-08 07:14:36,366 Step: 350, train_loss: 0.473739505708
2018-02-08 07:15:03,021 train_loss: 0.483947790966
2018-02-08 07:15:39,708 valid_loss: 0.620488781134, valid_acc: 0.824965132497
2018-02-08 07:15:39,723 Epoch: 6
2018-02-08 07:15:46,000 Step: 0, train_loss: 0.428036630154
2018-02-08 07:16:25,460 Step: 50, train_loss: 0.485914406478
2018-02-08 07:17:04,874 Step: 100, train_loss: 0.420372817963
2018-02-08 07:17:43,900 Step: 150, train_loss: 0.432272572368
2018-02-08 07:18:23,114 Step: 200, train_loss: 0.477212141976
2018-02-08 07:19:02,162 Step: 250, train_loss: 0.449297561795
2018-02-08 07:19:41,190 Step: 300, train_loss: 0.4695451767
2018-02-08 07:20:20,269 Step: 350, train_loss: 0.441096008718
2018-02-08 07:20:47,351 train_loss: 0.459539981762
2018-02-08 07:21:24,168 valid_loss: 0.45416482647, valid_acc: 0.864383561644
2018-02-08 07:21:24,583 Epoch: 7
2018-02-08 07:21:30,865 Step: 0, train_loss: 0.524668455124
2018-02-08 07:22:10,247 Step: 50, train_loss: 0.397977425158
2018-02-08 07:22:49,230 Step: 100, train_loss: 0.371802934259
2018-02-08 07:23:28,143 Step: 150, train_loss: 0.380650969148
2018-02-08 07:24:07,171 Step: 200, train_loss: 0.418712345883
2018-02-08 07:24:46,418 Step: 250, train_loss: 0.509031701013
2018-02-08 07:25:25,558 Step: 300, train_loss: 0.432666405886
2018-02-08 07:26:04,952 Step: 350, train_loss: 0.412796381861
2018-02-08 07:26:31,825 train_loss: 0.42411252118
2018-02-08 07:27:08,960 valid_loss: 0.297797477706, valid_acc: 0.89375
2018-02-08 07:27:09,369 Epoch: 8
2018-02-08 07:27:16,012 Step: 0, train_loss: 0.172472566366
2018-02-08 07:27:55,838 Step: 50, train_loss: 0.402789102942
2018-02-08 07:28:35,034 Step: 100, train_loss: 0.372889869809
2018-02-08 07:29:14,698 Step: 150, train_loss: 0.417072110474
2018-02-08 07:29:53,924 Step: 200, train_loss: 0.299950373843
2018-02-08 07:30:33,226 Step: 250, train_loss: 0.339278346077
2018-02-08 07:31:12,763 Step: 300, train_loss: 0.434468386322
2018-02-08 07:31:52,185 Step: 350, train_loss: 0.40790713843
2018-02-08 07:32:19,589 train_loss: 0.382962388923
2018-02-08 07:32:56,787 valid_loss: 0.920346318054, valid_acc: 0.783765347885
2018-02-08 07:32:56,801 Epoch: 9
2018-02-08 07:33:03,472 Step: 0, train_loss: 0.251384228468
2018-02-08 07:33:43,042 Step: 50, train_loss: 0.356446288526
2018-02-08 07:34:21,927 Step: 100, train_loss: 0.314412365258
2018-02-08 07:35:01,227 Step: 150, train_loss: 0.361856171042
2018-02-08 07:35:40,214 Step: 200, train_loss: 0.38880943913
2018-02-08 07:36:19,340 Step: 250, train_loss: 0.405349627733
2018-02-08 07:36:58,516 Step: 300, train_loss: 0.308397204727
2018-02-08 07:37:37,918 Step: 350, train_loss: 0.333122706711
2018-02-08 07:38:05,148 train_loss: 0.349673459668
2018-02-08 07:38:41,939 valid_loss: 0.484865292883, valid_acc: 0.879310344828
2018-02-08 07:38:41,951 Epoch: 10
2018-02-08 07:38:49,280 Step: 0, train_loss: 0.0847558155656
2018-02-08 07:39:28,540 Step: 50, train_loss: 0.311355609186
2018-02-08 07:40:07,772 Step: 100, train_loss: 0.374237967879
2018-02-08 07:40:47,018 Step: 150, train_loss: 0.302458890527
2018-02-08 07:41:25,954 Step: 200, train_loss: 0.338361418694
2018-02-08 07:42:05,265 Step: 250, train_loss: 0.333770387545
2018-02-08 07:42:44,318 Step: 300, train_loss: 0.421885836273
2018-02-08 07:43:23,250 Step: 350, train_loss: 0.394289279133
2018-02-08 07:43:50,379 train_loss: 0.358040008313
2018-02-08 07:44:27,431 valid_loss: 0.712769340621, valid_acc: 0.817808219178
2018-02-08 07:44:27,453 Epoch: 11
2018-02-08 07:44:33,805 Step: 0, train_loss: 0.53560513258
2018-02-08 07:45:12,734 Step: 50, train_loss: 0.331658834331
2018-02-08 07:45:51,773 Step: 100, train_loss: 0.374774541259
2018-02-08 07:46:31,026 Step: 150, train_loss: 0.312444711067
2018-02-08 07:47:10,247 Step: 200, train_loss: 0.297065981627
2018-02-08 07:47:49,423 Step: 250, train_loss: 0.362470652387
2018-02-08 07:48:28,708 Step: 300, train_loss: 0.332787495852
2018-02-08 07:49:07,537 Step: 350, train_loss: 0.314629435167
2018-02-08 07:49:34,631 train_loss: 0.332155320118
2018-02-08 07:50:12,307 valid_loss: 0.352197000802, valid_acc: 0.918620689655
2018-02-08 07:50:12,324 Epoch: 12
2018-02-08 07:50:20,235 Step: 0, train_loss: 0.360774278641
2018-02-08 07:50:59,884 Step: 50, train_loss: 0.324700111672
2018-02-08 07:51:38,978 Step: 100, train_loss: 0.312222054377
2018-02-08 07:52:18,197 Step: 150, train_loss: 0.279956904761
2018-02-08 07:52:57,659 Step: 200, train_loss: 0.293707919568
2018-02-08 07:53:36,790 Step: 250, train_loss: 0.367520233244
2018-02-08 07:54:15,618 Step: 300, train_loss: 0.300322107822
2018-02-08 07:54:54,984 Step: 350, train_loss: 0.362406802289
2018-02-08 07:55:22,650 train_loss: 0.32135515384
2018-02-08 07:56:00,029 valid_loss: 0.275903571975, valid_acc: 0.913816689466
2018-02-08 07:56:00,399 Epoch: 13
2018-02-08 07:56:07,878 Step: 0, train_loss: 0.767264425755
2018-02-08 07:56:47,276 Step: 50, train_loss: 0.268529383019
2018-02-08 07:57:26,195 Step: 100, train_loss: 0.270062544942
2018-02-08 07:58:05,438 Step: 150, train_loss: 0.279142119959
2018-02-08 07:58:44,564 Step: 200, train_loss: 0.327266942263
2018-02-08 07:59:23,758 Step: 250, train_loss: 0.311310796961
2018-02-08 08:00:03,047 Step: 300, train_loss: 0.276928918883
2018-02-08 08:00:42,214 Step: 350, train_loss: 0.329113800153
2018-02-08 08:01:09,468 train_loss: 0.307197668184
2018-02-08 08:01:46,562 valid_loss: 0.416541405279, valid_acc: 0.872562674095
2018-02-08 08:01:46,577 Epoch: 14
2018-02-08 08:01:53,715 Step: 0, train_loss: 0.354144632816
2018-02-08 08:02:32,900 Step: 50, train_loss: 0.293068805374
2018-02-08 08:03:12,169 Step: 100, train_loss: 0.301845862269
2018-02-08 08:03:51,270 Step: 150, train_loss: 0.26415868381
2018-02-08 08:04:30,810 Step: 200, train_loss: 0.296490906402
2018-02-08 08:05:10,018 Step: 250, train_loss: 0.247580045089
2018-02-08 08:05:49,309 Step: 300, train_loss: 0.276617486998
2018-02-08 08:06:28,454 Step: 350, train_loss: 0.339411130995
2018-02-08 08:06:55,621 train_loss: 0.296861117607
2018-02-08 08:07:32,400 valid_loss: 0.443539553405, valid_acc: 0.890581717452
2018-02-08 08:07:32,408 Epoch: 15
2018-02-08 08:07:39,169 Step: 0, train_loss: 0.24796693027
2018-02-08 08:08:18,800 Step: 50, train_loss: 0.33678958714
2018-02-08 08:08:57,949 Step: 100, train_loss: 0.340185127482
2018-02-08 08:09:37,319 Step: 150, train_loss: 0.297750807591
2018-02-08 08:10:16,429 Step: 200, train_loss: 0.269616992995
2018-02-08 08:10:55,500 Step: 250, train_loss: 0.315529343635
2018-02-08 08:11:34,670 Step: 300, train_loss: 0.311332678907
2018-02-08 08:12:13,505 Step: 350, train_loss: 0.263118263818
2018-02-08 08:12:40,486 train_loss: 0.302660311037
2018-02-08 08:13:17,868 valid_loss: 0.422480981993, valid_acc: 0.911401098901
2018-02-08 08:13:17,884 Epoch: 16
2018-02-08 08:13:24,162 Step: 0, train_loss: 0.344295442104
2018-02-08 08:14:03,724 Step: 50, train_loss: 0.296958036218
2018-02-08 08:14:42,760 Step: 100, train_loss: 0.283579482622
2018-02-08 08:15:21,947 Step: 150, train_loss: 0.277456284352
2018-02-08 08:16:01,264 Step: 200, train_loss: 0.258175038584
2018-02-08 08:16:40,660 Step: 250, train_loss: 0.29733488135
2018-02-08 08:17:19,616 Step: 300, train_loss: 0.30588687731
2018-02-08 08:17:58,544 Step: 350, train_loss: 0.23760911969
2018-02-08 08:18:25,869 train_loss: 0.286013417314
2018-02-08 08:19:02,784 valid_loss: 0.546196671888, valid_acc: 0.855836849508
2018-02-08 08:19:02,800 Epoch: 17
2018-02-08 08:19:09,238 Step: 0, train_loss: 0.0860035717487
2018-02-08 08:19:48,771 Step: 50, train_loss: 0.3042884022
2018-02-08 08:20:27,957 Step: 100, train_loss: 0.230809515789
2018-02-08 08:21:06,981 Step: 150, train_loss: 0.242034730949
2018-02-08 08:21:46,061 Step: 200, train_loss: 0.210110233426
2018-02-08 08:22:25,017 Step: 250, train_loss: 0.231781794652
2018-02-08 08:23:04,095 Step: 300, train_loss: 0.31291856721
2018-02-08 08:23:43,479 Step: 350, train_loss: 0.285660469159
2018-02-08 08:24:10,704 train_loss: 0.268961714537
2018-02-08 08:24:47,940 valid_loss: 0.30482346582, valid_acc: 0.9064697609
2018-02-08 08:24:47,963 Epoch: 18
2018-02-08 08:24:54,743 Step: 0, train_loss: 0.22633446753
2018-02-08 08:25:34,534 Step: 50, train_loss: 0.281637778021
2018-02-08 08:26:13,712 Step: 100, train_loss: 0.271034997627
2018-02-08 08:26:53,384 Step: 150, train_loss: 0.270251908619
2018-02-08 08:27:32,582 Step: 200, train_loss: 0.271528983805
2018-02-08 08:28:12,153 Step: 250, train_loss: 0.268297627531
2018-02-08 08:28:51,241 Step: 300, train_loss: 0.217757851928
2018-02-08 08:29:30,564 Step: 350, train_loss: 0.26600630641
2018-02-08 08:29:57,834 train_loss: 0.270617060245
2018-02-08 08:30:35,463 valid_loss: 0.376385434474, valid_acc: 0.889636608345
2018-02-08 08:30:35,478 Epoch: 19
2018-02-08 08:30:41,470 Step: 0, train_loss: 0.297929465771
2018-02-08 08:31:21,252 Step: 50, train_loss: 0.260856818557
2018-02-08 08:32:00,740 Step: 100, train_loss: 0.212467460008
2018-02-08 08:32:40,424 Step: 150, train_loss: 0.230172754787
2018-02-08 08:33:19,918 Step: 200, train_loss: 0.242142096963
2018-02-08 08:33:59,293 Step: 250, train_loss: 0.285580774471
2018-02-08 08:34:38,430 Step: 300, train_loss: 0.279215289131
2018-02-08 08:35:17,646 Step: 350, train_loss: 0.301323890761
2018-02-08 08:35:45,020 train_loss: 0.257454912385
2018-02-08 08:36:22,684 valid_loss: 0.349753663044, valid_acc: 0.907734056988
2018-02-08 08:36:22,705 Epoch: 20
2018-02-08 08:36:30,077 Step: 0, train_loss: 0.179702043533
2018-02-08 08:37:09,265 Step: 50, train_loss: 0.282284344397
2018-02-08 08:37:48,495 Step: 100, train_loss: 0.294122955017
2018-02-08 08:38:27,994 Step: 150, train_loss: 0.256890242621
2018-02-08 08:39:07,021 Step: 200, train_loss: 0.25389514681
2018-02-08 08:39:46,478 Step: 250, train_loss: 0.276782913953
2018-02-08 08:40:25,713 Step: 300, train_loss: 0.257376043275
2018-02-08 08:41:05,024 Step: 350, train_loss: 0.297899327353
2018-02-08 08:41:32,354 train_loss: 0.283970828313
2018-02-08 08:42:09,417 valid_loss: 0.347062059616, valid_acc: 0.901069518717
2018-02-08 08:42:09,434 Epoch: 21
2018-02-08 08:42:16,349 Step: 0, train_loss: 0.543364524841
2018-02-08 08:42:55,780 Step: 50, train_loss: 0.173769386634
2018-02-08 08:43:34,959 Step: 100, train_loss: 0.193494759873
2018-02-08 08:44:13,869 Step: 150, train_loss: 0.255937948711
2018-02-08 08:44:53,128 Step: 200, train_loss: 0.263342429027
2018-02-08 08:45:32,258 Step: 250, train_loss: 0.269737402909
2018-02-08 08:46:11,239 Step: 300, train_loss: 0.249178155214
2018-02-08 08:46:50,590 Step: 350, train_loss: 0.244237219319
2018-02-08 08:47:17,939 train_loss: 0.242121236061
2018-02-08 08:47:55,457 valid_loss: 0.206666894258, valid_acc: 0.948299319728
2018-02-08 08:47:55,854 Epoch: 22
2018-02-08 08:48:02,653 Step: 0, train_loss: 0.0333997942507
2018-02-08 08:48:42,004 Step: 50, train_loss: 0.268747732006
2018-02-08 08:49:21,527 Step: 100, train_loss: 0.267758103348
2018-02-08 08:50:00,684 Step: 150, train_loss: 0.229904074874
2018-02-08 08:50:40,120 Step: 200, train_loss: 0.245218592286
2018-02-08 08:51:19,513 Step: 250, train_loss: 0.224822287485
2018-02-08 08:51:58,851 Step: 300, train_loss: 0.261995025948
2018-02-08 08:52:38,213 Step: 350, train_loss: 0.243580671074
2018-02-08 08:53:05,365 train_loss: 0.253853101866
2018-02-08 08:53:42,561 valid_loss: 0.344441827076, valid_acc: 0.910041841004
2018-02-08 08:53:42,571 Epoch: 23
2018-02-08 08:53:49,023 Step: 0, train_loss: 0.257909238338
2018-02-08 08:54:28,710 Step: 50, train_loss: 0.208685844541
2018-02-08 08:55:07,935 Step: 100, train_loss: 0.24325726442
2018-02-08 08:55:47,357 Step: 150, train_loss: 0.206324726008
2018-02-08 08:56:26,821 Step: 200, train_loss: 0.221486383975
2018-02-08 08:57:06,123 Step: 250, train_loss: 0.216985911205
2018-02-08 08:57:45,135 Step: 300, train_loss: 0.207022386789
2018-02-08 08:58:24,682 Step: 350, train_loss: 0.19694362266
2018-02-08 08:58:51,793 train_loss: 0.213669311636
2018-02-08 08:59:29,126 valid_loss: 0.287108681001, valid_acc: 0.917910447761
2018-02-08 08:59:29,140 Epoch: 24
2018-02-08 08:59:36,781 Step: 0, train_loss: 0.15088891983
2018-02-08 09:00:16,439 Step: 50, train_loss: 0.260137308016
2018-02-08 09:00:55,887 Step: 100, train_loss: 0.218818442635
2018-02-08 09:01:35,234 Step: 150, train_loss: 0.232697951207
2018-02-08 09:02:14,185 Step: 200, train_loss: 0.252366035692
2018-02-08 09:02:53,405 Step: 250, train_loss: 0.263039754853
2018-02-08 09:03:32,512 Step: 300, train_loss: 0.202196941227
2018-02-08 09:04:11,024 Step: 350, train_loss: 0.222052329276
2018-02-08 09:04:37,863 train_loss: 0.246084985428
2018-02-08 09:05:14,856 valid_loss: 0.207569369782, valid_acc: 0.944672131148
2018-02-08 09:05:14,870 Epoch: 25
2018-02-08 09:05:22,203 Step: 0, train_loss: 0.464356303215
2018-02-08 09:06:01,549 Step: 50, train_loss: 0.297166820914
2018-02-08 09:06:40,659 Step: 100, train_loss: 0.211394091398
2018-02-08 09:07:19,220 Step: 150, train_loss: 0.254887866657
2018-02-08 09:07:58,119 Step: 200, train_loss: 0.263163370285
2018-02-08 09:08:37,300 Step: 250, train_loss: 0.265169337504
2018-02-08 09:09:16,503 Step: 300, train_loss: 0.248444965146
2018-02-08 09:09:55,564 Step: 350, train_loss: 0.202084899051
2018-02-08 09:10:22,786 train_loss: 0.246579729015
2018-02-08 09:11:00,158 valid_loss: 0.303762204367, valid_acc: 0.927685950413
2018-02-08 09:11:00,175 Epoch: 26
2018-02-08 09:11:07,582 Step: 0, train_loss: 0.221439942718
2018-02-08 09:11:47,187 Step: 50, train_loss: 0.205384263601
2018-02-08 09:12:26,259 Step: 100, train_loss: 0.262317396961
2018-02-08 09:13:05,550 Step: 150, train_loss: 0.210724111609
2018-02-08 09:13:44,529 Step: 200, train_loss: 0.214661621675
2018-02-08 09:14:23,609 Step: 250, train_loss: 0.199475501962
2018-02-08 09:15:02,556 Step: 300, train_loss: 0.223834362915
2018-02-08 09:15:41,516 Step: 350, train_loss: 0.273465052657
2018-02-08 09:16:08,772 train_loss: 0.236477768484
2018-02-08 09:16:46,235 valid_loss: 0.48046509289, valid_acc: 0.90798376184
2018-02-08 09:16:46,249 Epoch: 27
2018-02-08 09:16:52,818 Step: 0, train_loss: 0.120543561876
2018-02-08 09:17:32,358 Step: 50, train_loss: 0.151019680388
2018-02-08 09:18:11,544 Step: 100, train_loss: 0.182413558364
2018-02-08 09:18:50,660 Step: 150, train_loss: 0.216102168346
2018-02-08 09:19:29,663 Step: 200, train_loss: 0.223072630577
2018-02-08 09:20:08,971 Step: 250, train_loss: 0.264486972652
2018-02-08 09:20:48,051 Step: 300, train_loss: 0.266036487087
2018-02-08 09:21:27,091 Step: 350, train_loss: 0.229603573717
2018-02-08 09:21:54,301 train_loss: 0.230885975428
2018-02-08 09:22:31,322 valid_loss: 0.250929722145, valid_acc: 0.928180574555
2018-02-08 09:22:31,335 Epoch: 28
2018-02-08 09:22:37,927 Step: 0, train_loss: 0.435171723366
2018-02-08 09:23:17,514 Step: 50, train_loss: 0.20905551048
2018-02-08 09:23:56,684 Step: 100, train_loss: 0.188533840696
2018-02-08 09:24:35,986 Step: 150, train_loss: 0.256356021706
2018-02-08 09:25:15,365 Step: 200, train_loss: 0.226613799296
2018-02-08 09:25:54,463 Step: 250, train_loss: 0.272013826668
2018-02-08 09:26:33,789 Step: 300, train_loss: 0.186786060203
2018-02-08 09:27:13,405 Step: 350, train_loss: 0.260697538368
2018-02-08 09:27:40,528 train_loss: 0.229755587308
2018-02-08 09:28:17,973 valid_loss: 0.236375425625, valid_acc: 0.933287482806
2018-02-08 09:28:17,982 Epoch: 29
2018-02-08 09:28:25,666 Step: 0, train_loss: 0.00630580075085
2018-02-08 09:29:05,308 Step: 50, train_loss: 0.200551868379
2018-02-08 09:29:44,632 Step: 100, train_loss: 0.219004487284
2018-02-08 09:30:23,909 Step: 150, train_loss: 0.275885502361
2018-02-08 09:31:03,204 Step: 200, train_loss: 0.171020461731
2018-02-08 09:31:42,408 Step: 250, train_loss: 0.191173760537
2018-02-08 09:32:21,450 Step: 300, train_loss: 0.203379258569
2018-02-08 09:33:00,511 Step: 350, train_loss: 0.21795346126
2018-02-08 09:33:27,642 train_loss: 0.209520351562
2018-02-08 09:34:04,638 valid_loss: 0.330651610224, valid_acc: 0.926330150068
2018-02-08 09:34:04,647 Epoch: 30
2018-02-08 09:34:11,112 Step: 0, train_loss: 0.252677232027
2018-02-08 09:34:50,493 Step: 50, train_loss: 0.184793313835
2018-02-08 09:35:29,102 Step: 100, train_loss: 0.223431113791
2018-02-08 09:36:07,984 Step: 150, train_loss: 0.193638678975
2018-02-08 09:36:46,831 Step: 200, train_loss: 0.241591607071
2018-02-08 09:37:25,801 Step: 250, train_loss: 0.223254934624
2018-02-08 09:38:04,393 Step: 300, train_loss: 0.16714885266
2018-02-08 09:38:43,621 Step: 350, train_loss: 0.208458391884
2018-02-08 09:39:10,805 train_loss: 0.216291268222
2018-02-08 09:39:48,484 valid_loss: 0.285713368472, valid_acc: 0.913194444444
2018-02-08 09:39:48,503 Epoch: 31
2018-02-08 09:39:54,841 Step: 0, train_loss: 0.323844969273
2018-02-08 09:40:34,406 Step: 50, train_loss: 0.253435167689
2018-02-08 09:41:13,586 Step: 100, train_loss: 0.1768595153
2018-02-08 09:41:52,827 Step: 150, train_loss: 0.204084502682
2018-02-08 09:42:31,962 Step: 200, train_loss: 0.212023683041
2018-02-08 09:43:11,265 Step: 250, train_loss: 0.19180810676
2018-02-08 09:43:50,030 Step: 300, train_loss: 0.203558415147
2018-02-08 09:44:28,991 Step: 350, train_loss: 0.197115236297
2018-02-08 09:44:56,098 train_loss: 0.206271715538
2018-02-08 09:45:33,094 valid_loss: 0.293307108163, valid_acc: 0.922068965517
2018-02-08 09:45:33,106 Epoch: 32
2018-02-08 09:45:39,767 Step: 0, train_loss: 0.349287718534
2018-02-08 09:46:19,280 Step: 50, train_loss: 0.233926540129
2018-02-08 09:46:58,298 Step: 100, train_loss: 0.213925167192
2018-02-08 09:47:37,696 Step: 150, train_loss: 0.155107228979
2018-02-08 09:48:16,773 Step: 200, train_loss: 0.187844704408
2018-02-08 09:48:56,026 Step: 250, train_loss: 0.210627386011
2018-02-08 09:49:35,285 Step: 300, train_loss: 0.2343088145
2018-02-08 09:50:14,660 Step: 350, train_loss: 0.208623105492
2018-02-08 09:50:42,006 train_loss: 0.20760494446
2018-02-08 09:51:19,143 valid_loss: 0.365437540567, valid_acc: 0.915512465374
2018-02-08 09:51:19,160 Epoch: 33
2018-02-08 09:51:25,862 Step: 0, train_loss: 0.0117902494967
2018-02-08 09:52:05,691 Step: 50, train_loss: 0.252497152733
2018-02-08 09:52:44,766 Step: 100, train_loss: 0.13629080629
2018-02-08 09:53:24,069 Step: 150, train_loss: 0.14961290959
2018-02-08 09:54:03,214 Step: 200, train_loss: 0.126716808705
2018-02-08 09:54:42,130 Step: 250, train_loss: 0.131385537181
2018-02-08 09:55:21,373 Step: 300, train_loss: 0.132618989097
2018-02-08 09:56:00,221 Step: 350, train_loss: 0.125954172234
2018-02-08 09:56:27,433 train_loss: 0.153812893387
2018-02-08 09:57:04,167 valid_loss: 0.181030153789, valid_acc: 0.956908344733
2018-02-08 09:57:04,571 Epoch: 34
2018-02-08 09:57:11,479 Step: 0, train_loss: 0.175026535988
2018-02-08 09:57:51,344 Step: 50, train_loss: 0.162537875017
2018-02-08 09:58:30,472 Step: 100, train_loss: 0.1424432192
2018-02-08 09:59:09,345 Step: 150, train_loss: 0.118036644666
2018-02-08 09:59:48,926 Step: 200, train_loss: 0.149648370501
2018-02-08 10:00:27,385 Step: 250, train_loss: 0.11795214342
2018-02-08 10:01:06,799 Step: 300, train_loss: 0.138204861982
2018-02-08 10:01:45,696 Step: 350, train_loss: 0.167298074234
2018-02-08 10:02:12,950 train_loss: 0.144665451005
2018-02-08 10:02:50,105 valid_loss: 0.201418804768, valid_acc: 0.945890410959
2018-02-08 10:02:50,124 Epoch: 35
2018-02-08 10:02:56,867 Step: 0, train_loss: 0.0215052757412
2018-02-08 10:03:36,556 Step: 50, train_loss: 0.130068268506
2018-02-08 10:04:15,892 Step: 100, train_loss: 0.103929302602
2018-02-08 10:04:55,140 Step: 150, train_loss: 0.0999634554191
2018-02-08 10:05:34,525 Step: 200, train_loss: 0.143629186228
2018-02-08 10:06:13,849 Step: 250, train_loss: 0.149635336436
2018-02-08 10:06:53,016 Step: 300, train_loss: 0.121896030847
2018-02-08 10:07:32,171 Step: 350, train_loss: 0.144441714427
2018-02-08 10:07:59,248 train_loss: 0.131322272962
2018-02-08 10:08:37,600 valid_loss: 0.176099747088, valid_acc: 0.943681318681
2018-02-08 10:08:38,007 Epoch: 36
2018-02-08 10:08:45,596 Step: 0, train_loss: 0.170983731747
2018-02-08 10:09:25,217 Step: 50, train_loss: 0.123216934896
2018-02-08 10:10:04,689 Step: 100, train_loss: 0.121395294163
2018-02-08 10:10:44,005 Step: 150, train_loss: 0.119266714
2018-02-08 10:11:23,162 Step: 200, train_loss: 0.126678093541
2018-02-08 10:12:02,028 Step: 250, train_loss: 0.131096878406
2018-02-08 10:12:41,248 Step: 300, train_loss: 0.115945872217
2018-02-08 10:13:20,440 Step: 350, train_loss: 0.134443115843
2018-02-08 10:13:47,522 train_loss: 0.127623123944
2018-02-08 10:14:24,657 valid_loss: 0.120284527104, valid_acc: 0.957756232687
2018-02-08 10:14:25,018 Epoch: 37
2018-02-08 10:14:32,540 Step: 0, train_loss: 0.212257415056
2018-02-08 10:15:11,520 Step: 50, train_loss: 0.104989485802
2018-02-08 10:15:50,418 Step: 100, train_loss: 0.0859059212217
2018-02-08 10:16:29,651 Step: 150, train_loss: 0.129473151525
2018-02-08 10:17:08,656 Step: 200, train_loss: 0.0874001287064
2018-02-08 10:17:47,929 Step: 250, train_loss: 0.10466679872
2018-02-08 10:18:27,205 Step: 300, train_loss: 0.106683894298
2018-02-08 10:19:05,953 Step: 350, train_loss: 0.0800849164242
2018-02-08 10:19:33,031 train_loss: 0.10333675906
2018-02-08 10:20:10,223 valid_loss: 0.235985669123, valid_acc: 0.942994505495
2018-02-08 10:20:10,234 Epoch: 38
2018-02-08 10:20:16,970 Step: 0, train_loss: 0.175891578197
2018-02-08 10:20:56,760 Step: 50, train_loss: 0.155776117453
2018-02-08 10:21:36,014 Step: 100, train_loss: 0.11760609379
2018-02-08 10:22:15,298 Step: 150, train_loss: 0.0989723932557
2018-02-08 10:22:54,350 Step: 200, train_loss: 0.148769507529
2018-02-08 10:23:33,438 Step: 250, train_loss: 0.112730753319
2018-02-08 10:24:12,294 Step: 300, train_loss: 0.11834403838
2018-02-08 10:24:51,262 Step: 350, train_loss: 0.16872562923
2018-02-08 10:25:18,482 train_loss: 0.135122906133
2018-02-08 10:25:55,732 valid_loss: 0.183917490446, valid_acc: 0.94776119403
2018-02-08 10:25:55,747 Epoch: 39
2018-02-08 10:26:02,357 Step: 0, train_loss: 0.0603704042733
2018-02-08 10:26:41,846 Step: 50, train_loss: 0.118627341478
2018-02-08 10:27:21,088 Step: 100, train_loss: 0.0986966462852
2018-02-08 10:28:00,151 Step: 150, train_loss: 0.112618498327
2018-02-08 10:28:39,413 Step: 200, train_loss: 0.106521655442
2018-02-08 10:29:18,605 Step: 250, train_loss: 0.148655086318
2018-02-08 10:29:57,418 Step: 300, train_loss: 0.106628152467
2018-02-08 10:30:36,329 Step: 350, train_loss: 0.106743129445
2018-02-08 10:31:03,487 train_loss: 0.115051524342
2018-02-08 10:31:40,435 valid_loss: 0.186104406051, valid_acc: 0.957084468665
2018-02-08 10:31:40,447 Epoch: 40
2018-02-08 10:31:46,668 Step: 0, train_loss: 0.158914133906
2018-02-08 10:32:26,081 Step: 50, train_loss: 0.136628612289
2018-02-08 10:33:05,351 Step: 100, train_loss: 0.144415949527
2018-02-08 10:33:44,601 Step: 150, train_loss: 0.106224691607
2018-02-08 10:34:23,601 Step: 200, train_loss: 0.0943192047579
2018-02-08 10:35:02,769 Step: 250, train_loss: 0.142451216318
2018-02-08 10:35:41,919 Step: 300, train_loss: 0.144913290194
2018-02-08 10:36:21,228 Step: 350, train_loss: 0.134411377069
2018-02-08 10:36:48,312 train_loss: 0.139742319437
2018-02-08 10:37:25,280 valid_loss: 0.175772256555, valid_acc: 0.955862068966
2018-02-08 10:37:25,295 Epoch: 41
2018-02-08 10:37:32,902 Step: 0, train_loss: 0.0104509992525
2018-02-08 10:38:12,367 Step: 50, train_loss: 0.121866718442
2018-02-08 10:38:51,281 Step: 100, train_loss: 0.0977474752907
2018-02-08 10:39:30,618 Step: 150, train_loss: 0.115120677853
2018-02-08 10:40:09,357 Step: 200, train_loss: 0.150676731546
2018-02-08 10:40:48,338 Step: 250, train_loss: 0.108237325724
2018-02-08 10:41:27,438 Step: 300, train_loss: 0.141844027117
2018-02-08 10:42:06,809 Step: 350, train_loss: 0.160067028878
2018-02-08 10:42:33,314 train_loss: 0.131496654015
2018-02-08 10:43:09,600 valid_loss: 0.355658454657, valid_acc: 0.923669467787
2018-02-08 10:43:09,614 Epoch: 42
2018-02-08 10:43:17,484 Step: 0, train_loss: 0.092423170805
2018-02-08 10:43:56,746 Step: 50, train_loss: 0.111778941667
2018-02-08 10:44:35,928 Step: 100, train_loss: 0.0980367646739
2018-02-08 10:45:14,590 Step: 150, train_loss: 0.094327784765
2018-02-08 10:45:53,853 Step: 200, train_loss: 0.147541056536
2018-02-08 10:46:32,935 Step: 250, train_loss: 0.165341766821
2018-02-08 10:47:12,095 Step: 300, train_loss: 0.098063742565
2018-02-08 10:47:50,977 Step: 350, train_loss: 0.148423125825
2018-02-08 10:48:18,160 train_loss: 0.124285530794
2018-02-08 10:48:55,661 valid_loss: 0.273674130447, valid_acc: 0.939393939394
2018-02-08 10:48:55,682 Epoch: 43
2018-02-08 10:49:02,459 Step: 0, train_loss: 0.00383316143416
2018-02-08 10:49:41,885 Step: 50, train_loss: 0.102257693456
2018-02-08 10:50:21,012 Step: 100, train_loss: 0.127354065189
2018-02-08 10:51:00,370 Step: 150, train_loss: 0.108209116608
2018-02-08 10:51:39,626 Step: 200, train_loss: 0.0889486351982
2018-02-08 10:52:18,557 Step: 250, train_loss: 0.0856196051859
2018-02-08 10:52:57,721 Step: 300, train_loss: 0.110179360276
2018-02-08 10:53:36,863 Step: 350, train_loss: 0.116206767294
2018-02-08 10:54:03,994 train_loss: 0.106728582093
2018-02-08 10:54:41,706 valid_loss: 0.145430466278, valid_acc: 0.964619492657
2018-02-08 10:54:41,718 Epoch: 44
2018-02-08 10:54:48,255 Step: 0, train_loss: 0.143416643143
2018-02-08 10:55:28,009 Step: 50, train_loss: 0.132007383418
2018-02-08 10:56:06,912 Step: 100, train_loss: 0.144013040718
2018-02-08 10:56:46,176 Step: 150, train_loss: 0.115512719385
2018-02-08 10:57:25,071 Step: 200, train_loss: 0.110772312011
2018-02-08 10:58:04,097 Step: 250, train_loss: 0.126103327377
2018-02-08 10:58:43,181 Step: 300, train_loss: 0.0851140829199
2018-02-08 10:59:22,517 Step: 350, train_loss: 0.105674620513
2018-02-08 10:59:49,726 train_loss: 0.121883074007
2018-02-08 11:00:26,905 valid_loss: 0.156113503228, valid_acc: 0.951815642458
2018-02-08 11:00:26,920 Epoch: 45
2018-02-08 11:00:34,152 Step: 0, train_loss: 0.0985786095262
2018-02-08 11:01:13,222 Step: 50, train_loss: 0.112767858201
2018-02-08 11:01:52,518 Step: 100, train_loss: 0.102102269148
2018-02-08 11:02:31,614 Step: 150, train_loss: 0.121456349213
2018-02-08 11:03:10,466 Step: 200, train_loss: 0.11589477964
2018-02-08 11:03:49,051 Step: 250, train_loss: 0.0804842907307
2018-02-08 11:04:28,080 Step: 300, train_loss: 0.0927436439972
2018-02-08 11:05:06,981 Step: 350, train_loss: 0.0837347090617
2018-02-08 11:05:33,741 train_loss: 0.105642989295
2018-02-08 11:06:10,968 valid_loss: 0.198974081629, valid_acc: 0.945741758242
2018-02-08 11:06:10,987 Epoch: 46
2018-02-08 11:06:17,101 Step: 0, train_loss: 0.00692945066839
2018-02-08 11:06:56,874 Step: 50, train_loss: 0.122421515351
2018-02-08 11:07:35,921 Step: 100, train_loss: 0.0847906325664
2018-02-08 11:08:15,085 Step: 150, train_loss: 0.100808890872
2018-02-08 11:08:54,220 Step: 200, train_loss: 0.0951953783398
2018-02-08 11:09:33,505 Step: 250, train_loss: 0.129538461028
2018-02-08 11:10:12,632 Step: 300, train_loss: 0.121344294809
2018-02-08 11:10:51,638 Step: 350, train_loss: 0.139526216828
2018-02-08 11:11:18,798 train_loss: 0.116658141196
2018-02-08 11:11:56,586 valid_loss: 0.348051450651, valid_acc: 0.93519781719
2018-02-08 11:11:56,602 Epoch: 47
2018-02-08 11:12:03,893 Step: 0, train_loss: 0.229247018695
2018-02-08 11:12:43,275 Step: 50, train_loss: 0.121068327269
2018-02-08 11:13:22,533 Step: 100, train_loss: 0.0852332531149
2018-02-08 11:14:01,925 Step: 150, train_loss: 0.0953923657769
2018-02-08 11:14:40,962 Step: 200, train_loss: 0.0938805775251
2018-02-08 11:15:19,987 Step: 250, train_loss: 0.12204523962
2018-02-08 11:15:59,106 Step: 300, train_loss: 0.0756463439949
2018-02-08 11:16:38,229 Step: 350, train_loss: 0.116269382015
2018-02-08 11:17:05,466 train_loss: 0.109011587879
2018-02-08 11:17:42,062 valid_loss: 0.207840935281, valid_acc: 0.934903047091
2018-02-08 11:17:42,081 Epoch: 48
2018-02-08 11:17:49,157 Step: 0, train_loss: 0.352353960276
2018-02-08 11:18:28,282 Step: 50, train_loss: 0.138334128279
2018-02-08 11:19:07,178 Step: 100, train_loss: 0.0816414563986
2018-02-08 11:19:46,175 Step: 150, train_loss: 0.0706646141643
2018-02-08 11:20:25,180 Step: 200, train_loss: 0.0873161867913
2018-02-08 11:21:04,140 Step: 250, train_loss: 0.0920727565198
2018-02-08 11:21:43,299 Step: 300, train_loss: 0.0974019565858
2018-02-08 11:22:22,611 Step: 350, train_loss: 0.0996940368693
2018-02-08 11:22:49,622 train_loss: 0.107837877838
2018-02-08 11:23:26,714 valid_loss: 0.299455409065, valid_acc: 0.95
2018-02-08 11:23:26,731 Epoch: 49
2018-02-08 11:23:33,092 Step: 0, train_loss: 0.151935920119
2018-02-08 11:24:12,634 Step: 50, train_loss: 0.0839334326657
2018-02-08 11:24:51,750 Step: 100, train_loss: 0.0812960022152
2018-02-08 11:25:31,123 Step: 150, train_loss: 0.0589150993992
2018-02-08 11:26:10,345 Step: 200, train_loss: 0.0859218065813
2018-02-08 11:26:49,640 Step: 250, train_loss: 0.0904459609278
2018-02-08 11:27:28,550 Step: 300, train_loss: 0.0899850283295
2018-02-08 11:28:07,744 Step: 350, train_loss: 0.0821299430158
2018-02-08 11:28:35,234 train_loss: 0.0849024621378
2018-02-08 11:29:12,117 valid_loss: 0.32459095307, valid_acc: 0.946185286104
2018-02-08 11:29:12,127 Epoch: 50
2018-02-08 11:29:19,645 Step: 0, train_loss: 0.141287192702
2018-02-08 11:29:59,074 Step: 50, train_loss: 0.0884957447462
2018-02-08 11:30:37,585 Step: 100, train_loss: 0.0746286170138
2018-02-08 11:31:16,684 Step: 150, train_loss: 0.0654072355549
2018-02-08 11:31:55,437 Step: 200, train_loss: 0.0630393121083
2018-02-08 11:32:34,662 Step: 250, train_loss: 0.0711013855226
2018-02-08 11:33:14,206 Step: 300, train_loss: 0.0638024508639
2018-02-08 11:33:53,544 Step: 350, train_loss: 0.0662298676209
2018-02-08 11:34:20,723 train_loss: 0.0697731125734
2018-02-08 11:34:58,120 valid_loss: 0.254076052682, valid_acc: 0.951388888889
2018-02-08 11:34:58,141 Epoch: 51
2018-02-08 11:35:05,362 Step: 0, train_loss: 0.0133554404601
2018-02-08 11:35:45,338 Step: 50, train_loss: 0.0727661993122
2018-02-08 11:36:24,645 Step: 100, train_loss: 0.0739468987426
2018-02-08 11:37:04,138 Step: 150, train_loss: 0.0862448222074
2018-02-08 11:37:43,709 Step: 200, train_loss: 0.0628224608395
2018-02-08 11:38:22,778 Step: 250, train_loss: 0.0715775823209
2018-02-08 11:39:02,016 Step: 300, train_loss: 0.0714170821215
2018-02-08 11:39:41,520 Step: 350, train_loss: 0.0557733847084
2018-02-08 11:40:08,870 train_loss: 0.0721926612667
2018-02-08 11:40:46,814 valid_loss: 0.311670632531, valid_acc: 0.955213903743
2018-02-08 11:40:46,828 Epoch: 52
2018-02-08 11:40:54,202 Step: 0, train_loss: 0.170492649078
2018-02-08 11:41:33,438 Step: 50, train_loss: 0.0756629661517
2018-02-08 11:42:12,688 Step: 100, train_loss: 0.0611693806507
2018-02-08 11:42:51,522 Step: 150, train_loss: 0.0498164343007
2018-02-08 11:43:30,140 Step: 200, train_loss: 0.0563719447359
2018-02-08 11:44:09,403 Step: 250, train_loss: 0.0757586305245
2018-02-08 11:44:48,522 Step: 300, train_loss: 0.0871113193408
2018-02-08 11:45:27,677 Step: 350, train_loss: 0.0901202868228
2018-02-08 11:45:54,796 train_loss: 0.0750911898499
2018-02-08 11:46:32,060 valid_loss: 0.141853658299, valid_acc: 0.968622100955
2018-02-08 11:46:32,073 Epoch: 53
2018-02-08 11:46:37,865 Step: 0, train_loss: 0.0167170893401
2018-02-08 11:47:17,336 Step: 50, train_loss: 0.0874329989636
2018-02-08 11:47:56,448 Step: 100, train_loss: 0.0754602001858
2018-02-08 11:48:35,222 Step: 150, train_loss: 0.0913924669521
2018-02-08 11:49:14,065 Step: 200, train_loss: 0.0433895663626
2018-02-08 11:49:53,167 Step: 250, train_loss: 0.0826179614392
2018-02-08 11:50:32,343 Step: 300, train_loss: 0.065561854894
2018-02-08 11:51:11,490 Step: 350, train_loss: 0.0642045021895
2018-02-08 11:51:38,539 train_loss: 0.0759069382656
2018-02-08 11:52:15,665 valid_loss: 0.102087152831, valid_acc: 0.96511627907
2018-02-08 11:52:16,064 Epoch: 54
2018-02-08 11:52:22,328 Step: 0, train_loss: 0.00210105045699
2018-02-08 11:53:01,808 Step: 50, train_loss: 0.0779410176375
2018-02-08 11:53:40,794 Step: 100, train_loss: 0.0693414111109
2018-02-08 11:54:19,742 Step: 150, train_loss: 0.08655296357
2018-02-08 11:54:58,855 Step: 200, train_loss: 0.0769941111316
2018-02-08 11:55:38,101 Step: 250, train_loss: 0.0861504750582
2018-02-08 11:56:17,453 Step: 300, train_loss: 0.09185037705
2018-02-08 11:56:56,791 Step: 350, train_loss: 0.073068167778
2018-02-08 11:57:23,991 train_loss: 0.0821157753268
2018-02-08 11:58:01,611 valid_loss: 0.100221880763, valid_acc: 0.967514124294
2018-02-08 11:58:02,046 Epoch: 55
2018-02-08 11:58:08,069 Step: 0, train_loss: 0.00420130603015
2018-02-08 11:58:48,027 Step: 50, train_loss: 0.0840733309765
2018-02-08 11:59:27,546 Step: 100, train_loss: 0.0550444607646
2018-02-08 12:00:06,903 Step: 150, train_loss: 0.0770709169883
2018-02-08 12:00:46,272 Step: 200, train_loss: 0.078436932771
2018-02-08 12:01:25,774 Step: 250, train_loss: 0.082737890624
2018-02-08 12:02:05,295 Step: 300, train_loss: 0.0480541651417
2018-02-08 12:02:44,351 Step: 350, train_loss: 0.0716394353518
2018-02-08 12:03:11,345 train_loss: 0.0763087848575
2018-02-08 12:03:48,639 valid_loss: 0.181740348424, valid_acc: 0.946132596685
2018-02-08 12:03:48,650 Epoch: 56
2018-02-08 12:03:56,388 Step: 0, train_loss: 0.0793619975448
2018-02-08 12:04:35,446 Step: 50, train_loss: 0.0706430613762
2018-02-08 12:05:14,432 Step: 100, train_loss: 0.0561803915165
2018-02-08 12:05:53,580 Step: 150, train_loss: 0.0459158822382
2018-02-08 12:06:32,613 Step: 200, train_loss: 0.0444715306442
2018-02-08 12:07:11,590 Step: 250, train_loss: 0.0712052035716
2018-02-08 12:07:50,715 Step: 300, train_loss: 0.0643043453619
2018-02-08 12:08:29,439 Step: 350, train_loss: 0.0831232488592
2018-02-08 12:08:56,277 train_loss: 0.0648163902204
2018-02-08 12:09:33,650 valid_loss: 0.309702090831, valid_acc: 0.94342291372
2018-02-08 12:09:33,664 Epoch: 57
2018-02-08 12:09:40,866 Step: 0, train_loss: 0.0233683586121
2018-02-08 12:10:20,298 Step: 50, train_loss: 0.0542636083206
2018-02-08 12:10:59,441 Step: 100, train_loss: 0.0508803882741
2018-02-08 12:11:38,767 Step: 150, train_loss: 0.0559175600321
2018-02-08 12:12:17,831 Step: 200, train_loss: 0.0741733363783
2018-02-08 12:12:56,846 Step: 250, train_loss: 0.115814340108
2018-02-08 12:13:36,053 Step: 300, train_loss: 0.0660632328095
2018-02-08 12:14:14,808 Step: 350, train_loss: 0.0570111611974
2018-02-08 12:14:42,293 train_loss: 0.0729690068521
2018-02-08 12:15:19,234 valid_loss: 0.210146329082, valid_acc: 0.96314325452
2018-02-08 12:15:19,253 Epoch: 58
2018-02-08 12:15:25,437 Step: 0, train_loss: 0.474870532751
2018-02-08 12:16:04,986 Step: 50, train_loss: 0.0680223459739
2018-02-08 12:16:44,037 Step: 100, train_loss: 0.0530043774191
2018-02-08 12:17:23,228 Step: 150, train_loss: 0.0801644948265
2018-02-08 12:18:02,386 Step: 200, train_loss: 0.0655324186228
2018-02-08 12:18:41,416 Step: 250, train_loss: 0.0846132698032
2018-02-08 12:19:20,411 Step: 300, train_loss: 0.0806560890173
2018-02-08 12:19:59,558 Step: 350, train_loss: 0.0954319177102
2018-02-08 12:20:26,520 train_loss: 0.0767524790112
2018-02-08 12:21:03,432 valid_loss: 0.15282135778, valid_acc: 0.96301369863
2018-02-08 12:21:03,444 Epoch: 59
2018-02-08 12:21:09,812 Step: 0, train_loss: 0.0254670772702
2018-02-08 12:21:50,014 Step: 50, train_loss: 0.0654281018209
2018-02-08 12:22:29,387 Step: 100, train_loss: 0.0647881948639
2018-02-08 12:23:08,382 Step: 150, train_loss: 0.0956311794993
2018-02-08 12:23:47,685 Step: 200, train_loss: 0.100964754383
2018-02-08 12:24:27,131 Step: 250, train_loss: 0.0768088880926
2018-02-08 12:25:06,154 Step: 300, train_loss: 0.0649446569436
2018-02-08 12:25:45,279 Step: 350, train_loss: 0.0677346419357
2018-02-08 12:26:12,538 train_loss: 0.0859716449215
2018-02-08 12:26:49,898 valid_loss: 0.104756389066, valid_acc: 0.973611111111
2018-02-08 12:26:49,912 Epoch: 60
2018-02-08 12:26:57,429 Step: 0, train_loss: 0.177150890231
2018-02-08 12:27:37,025 Step: 50, train_loss: 0.0699889117526
2018-02-08 12:28:16,215 Step: 100, train_loss: 0.0688932152453
2018-02-08 12:28:55,499 Step: 150, train_loss: 0.0515930833749
2018-02-08 12:29:34,854 Step: 200, train_loss: 0.049022323883
2018-02-08 12:30:14,178 Step: 250, train_loss: 0.0570216819143
2018-02-08 12:30:53,666 Step: 300, train_loss: 0.047498158479
2018-02-08 12:31:32,674 Step: 350, train_loss: 0.0729138249956
2018-02-08 12:31:59,700 train_loss: 0.0652801548285
2018-02-08 12:32:37,244 valid_loss: 0.0822663608986, valid_acc: 0.976839237057
2018-02-08 12:32:37,611 Epoch: 61
2018-02-08 12:32:43,690 Step: 0, train_loss: 0.00155682035256
2018-02-08 12:33:23,009 Step: 50, train_loss: 0.0515333764127
2018-02-08 12:34:02,096 Step: 100, train_loss: 0.0663599775743
2018-02-08 12:34:40,874 Step: 150, train_loss: 0.0802266256791
2018-02-08 12:35:19,902 Step: 200, train_loss: 0.0902244288893
2018-02-08 12:35:58,678 Step: 250, train_loss: 0.067587751993
2018-02-08 12:36:37,523 Step: 300, train_loss: 0.052554817326
2018-02-08 12:37:16,178 Step: 350, train_loss: 0.0504357317428
2018-02-08 12:37:43,229 train_loss: 0.067431717996
2018-02-08 12:38:19,940 valid_loss: 0.167826436999, valid_acc: 0.963888888889
2018-02-08 12:38:19,958 Epoch: 62
2018-02-08 12:38:26,408 Step: 0, train_loss: 0.000530030985828
2018-02-08 12:39:06,411 Step: 50, train_loss: 0.0514532306558
2018-02-08 12:39:45,462 Step: 100, train_loss: 0.0830527642323
2018-02-08 12:40:24,827 Step: 150, train_loss: 0.0572471656674
2018-02-08 12:41:04,188 Step: 200, train_loss: 0.065700881089
2018-02-08 12:41:43,443 Step: 250, train_loss: 0.0514434520528
2018-02-08 12:42:22,676 Step: 300, train_loss: 0.0621857901989
2018-02-08 12:43:01,993 Step: 350, train_loss: 0.0630181113747
2018-02-08 12:43:29,286 train_loss: 0.061492955903
2018-02-08 12:44:05,854 valid_loss: 0.183464921533, valid_acc: 0.968619246862
2018-02-08 12:44:05,874 Epoch: 63
2018-02-08 12:44:11,972 Step: 0, train_loss: 0.0352046228945
2018-02-08 12:44:51,993 Step: 50, train_loss: 0.0817416313838
2018-02-08 12:45:31,344 Step: 100, train_loss: 0.0662755411316
2018-02-08 12:46:10,705 Step: 150, train_loss: 0.0702292413125
2018-02-08 12:46:50,027 Step: 200, train_loss: 0.0736129913654
2018-02-08 12:47:29,240 Step: 250, train_loss: 0.0519530229853
2018-02-08 12:48:08,379 Step: 300, train_loss: 0.0521642006887
2018-02-08 12:48:47,883 Step: 350, train_loss: 0.0666226329643
2018-02-08 12:49:15,185 train_loss: 0.0690317102005
2018-02-08 12:49:52,504 valid_loss: 0.152081975254, valid_acc: 0.966621253406
2018-02-08 12:49:52,520 Epoch: 64
2018-02-08 12:50:00,289 Step: 0, train_loss: 0.144129037857
2018-02-08 12:50:39,944 Step: 50, train_loss: 0.0939247852028
2018-02-08 12:51:19,331 Step: 100, train_loss: 0.0701215630607
2018-02-08 12:51:58,784 Step: 150, train_loss: 0.0532904971391
2018-02-08 12:52:38,110 Step: 200, train_loss: 0.076742236407
2018-02-08 12:53:17,421 Step: 250, train_loss: 0.0444340056344
2018-02-08 12:53:56,664 Step: 300, train_loss: 0.0748651379254
2018-02-08 12:54:36,133 Step: 350, train_loss: 0.0592138436157
2018-02-08 12:55:03,422 train_loss: 0.0679581133131
2018-02-08 12:55:41,020 valid_loss: 0.159588095508, valid_acc: 0.974358974359
2018-02-08 12:55:41,034 Epoch: 65
2018-02-08 12:55:47,592 Step: 0, train_loss: 0.0205664113164
2018-02-08 12:56:27,269 Step: 50, train_loss: 0.0779513009713
2018-02-08 12:57:06,614 Step: 100, train_loss: 0.0833708885149
2018-02-08 12:57:45,846 Step: 150, train_loss: 0.0425991670712
2018-02-08 12:58:24,795 Step: 200, train_loss: 0.0638039004477
2018-02-08 12:59:04,082 Step: 250, train_loss: 0.0542326296668
2018-02-08 12:59:43,425 Step: 300, train_loss: 0.0633085284958
2018-02-08 13:00:22,906 Step: 350, train_loss: 0.05852987063
2018-02-08 13:00:50,293 train_loss: 0.0635352214545
2018-02-08 13:01:27,039 valid_loss: 0.241535479974, valid_acc: 0.949724517906
2018-02-08 13:01:27,051 Epoch: 66
2018-02-08 13:01:33,283 Step: 0, train_loss: 0.00409656111151
2018-02-08 13:02:13,252 Step: 50, train_loss: 0.0545536687976
2018-02-08 13:02:52,529 Step: 100, train_loss: 0.0582057225378
2018-02-08 13:03:31,562 Step: 150, train_loss: 0.0456108113396
2018-02-08 13:04:10,830 Step: 200, train_loss: 0.0763142979308
2018-02-08 13:04:50,085 Step: 250, train_loss: 0.0760206421267
2018-02-08 13:05:29,048 Step: 300, train_loss: 0.0877027315239
2018-02-08 13:06:08,321 Step: 350, train_loss: 0.0669800829748
2018-02-08 13:06:35,404 train_loss: 0.0700109010216
2018-02-08 13:07:12,522 valid_loss: 0.342666679674, valid_acc: 0.962068965517
2018-02-08 13:07:12,539 Epoch: 67
2018-02-08 13:07:19,182 Step: 0, train_loss: 0.0206598173827
2018-02-08 13:07:59,011 Step: 50, train_loss: 0.0616815029513
2018-02-08 13:08:38,326 Step: 100, train_loss: 0.0529264030594
2018-02-08 13:09:17,489 Step: 150, train_loss: 0.0397093665879
2018-02-08 13:09:56,488 Step: 200, train_loss: 0.0567016805796
2018-02-08 13:10:35,584 Step: 250, train_loss: 0.0799034989451
2018-02-08 13:11:14,667 Step: 300, train_loss: 0.0666247489653
2018-02-08 13:11:54,089 Step: 350, train_loss: 0.0439368254424
2018-02-08 13:12:21,178 train_loss: 0.0614497456524
2018-02-08 13:12:58,234 valid_loss: 0.214901817381, valid_acc: 0.965734265734
2018-02-08 13:12:58,248 Epoch: 68
2018-02-08 13:13:04,655 Step: 0, train_loss: 0.0373424962163
2018-02-08 13:13:44,169 Step: 50, train_loss: 0.0558498818381
2018-02-08 13:14:23,050 Step: 100, train_loss: 0.0845147569536
2018-02-08 13:15:02,210 Step: 150, train_loss: 0.0438750012137
2018-02-08 13:15:41,330 Step: 200, train_loss: 0.056720389449
2018-02-08 13:16:20,548 Step: 250, train_loss: 0.0727304929611
2018-02-08 13:16:59,879 Step: 300, train_loss: 0.0582532540883
2018-02-08 13:17:39,132 Step: 350, train_loss: 0.0614682033018
2018-02-08 13:18:06,375 train_loss: 0.0653070741008
2018-02-08 13:18:43,955 valid_loss: 0.107338226723, valid_acc: 0.970708446866
2018-02-08 13:18:43,969 Epoch: 69
2018-02-08 13:18:51,692 Step: 0, train_loss: 0.151717931032
2018-02-08 13:19:31,261 Step: 50, train_loss: 0.0815184464655
2018-02-08 13:20:10,489 Step: 100, train_loss: 0.051524770984
2018-02-08 13:20:49,755 Step: 150, train_loss: 0.0364492698817
2018-02-08 13:21:28,889 Step: 200, train_loss: 0.0627948238153
2018-02-08 13:22:07,782 Step: 250, train_loss: 0.0473898215342
2018-02-08 13:22:47,169 Step: 300, train_loss: 0.0380419607298
2018-02-08 13:23:26,391 Step: 350, train_loss: 0.0503122478096
2018-02-08 13:23:53,676 train_loss: 0.0553429643801
2018-02-08 13:24:31,222 valid_loss: 0.178594221168, valid_acc: 0.96437994723
2018-02-08 13:24:31,242 Epoch: 70
2018-02-08 13:24:37,718 Step: 0, train_loss: 0.0371952056885
2018-02-08 13:25:17,446 Step: 50, train_loss: 0.069315696815
2018-02-08 13:25:56,478 Step: 100, train_loss: 0.071802294997
2018-02-08 13:26:35,554 Step: 150, train_loss: 0.0441119816166
2018-02-08 13:27:14,615 Step: 200, train_loss: 0.074603827903
2018-02-08 13:27:53,461 Step: 250, train_loss: 0.0666756153379
2018-02-08 13:28:32,596 Step: 300, train_loss: 0.0530043195661
2018-02-08 13:29:11,886 Step: 350, train_loss: 0.0704135602576
2018-02-08 13:29:38,508 train_loss: 0.0669945401271
2018-02-08 13:30:15,889 valid_loss: 0.241461013005, valid_acc: 0.948132780083
2018-02-08 13:30:15,903 Epoch: 71
2018-02-08 13:30:22,706 Step: 0, train_loss: 0.00527811050415
2018-02-08 13:31:02,362 Step: 50, train_loss: 0.0481775957486
2018-02-08 13:31:41,352 Step: 100, train_loss: 0.0599066608574
2018-02-08 13:32:20,409 Step: 150, train_loss: 0.0686855419388
2018-02-08 13:32:59,800 Step: 200, train_loss: 0.0501339040324
2018-02-08 13:33:38,877 Step: 250, train_loss: 0.0751450577809
2018-02-08 13:34:18,032 Step: 300, train_loss: 0.0506459061423
2018-02-08 13:34:57,267 Step: 350, train_loss: 0.0597256529052
2018-02-08 13:35:24,505 train_loss: 0.0610755539866
2018-02-08 13:36:01,707 valid_loss: 0.141580141015, valid_acc: 0.971140939597
2018-02-08 13:36:01,718 Epoch: 72
2018-02-08 13:36:08,456 Step: 0, train_loss: 0.0191184151918
2018-02-08 13:36:48,174 Step: 50, train_loss: 0.0832471236907
2018-02-08 13:37:27,246 Step: 100, train_loss: 0.0593123572972
2018-02-08 13:38:06,535 Step: 150, train_loss: 0.0689060446352
2018-02-08 13:38:45,425 Step: 200, train_loss: 0.0480898797233
2018-02-08 13:39:24,643 Step: 250, train_loss: 0.0624940274621
2018-02-08 13:40:04,006 Step: 300, train_loss: 0.0383619909803
2018-02-08 13:40:42,984 Step: 350, train_loss: 0.0485110190674
2018-02-08 13:41:10,360 train_loss: 0.0661436243816
2018-02-08 13:41:47,958 valid_loss: 0.222948071241, valid_acc: 0.952445652174
2018-02-08 13:41:47,971 Epoch: 73
2018-02-08 13:41:55,773 Step: 0, train_loss: 0.0772298946977
2018-02-08 13:42:35,247 Step: 50, train_loss: 0.0402429960924
2018-02-08 13:43:14,572 Step: 100, train_loss: 0.0522896195279
2018-02-08 13:43:53,837 Step: 150, train_loss: 0.0465467251177
2018-02-08 13:44:33,214 Step: 200, train_loss: 0.0439773779954
2018-02-08 13:45:12,370 Step: 250, train_loss: 0.0734216617554
2018-02-08 13:45:51,462 Step: 300, train_loss: 0.0362881046138
2018-02-08 13:46:30,848 Step: 350, train_loss: 0.037647622964
2018-02-08 13:46:57,916 train_loss: 0.0553239849252
2018-02-08 13:47:35,643 valid_loss: 0.311405234932, valid_acc: 0.949591280654
2018-02-08 13:47:35,660 Epoch: 74
2018-02-08 13:47:43,026 Step: 0, train_loss: 0.0829577744007
2018-02-08 13:48:22,636 Step: 50, train_loss: 0.034783032946
2018-02-08 13:49:01,816 Step: 100, train_loss: 0.0421712596033
2018-02-08 13:49:40,757 Step: 150, train_loss: 0.0350308606483
2018-02-08 13:50:20,013 Step: 200, train_loss: 0.0508658417509
2018-02-08 13:50:59,094 Step: 250, train_loss: 0.0563130641473
2018-02-08 13:51:38,358 Step: 300, train_loss: 0.0674310385785
2018-02-08 13:52:17,423 Step: 350, train_loss: 0.0431652453489
2018-02-08 13:52:44,699 train_loss: 0.0515933496826
2018-02-08 13:53:21,331 valid_loss: 0.169756247798, valid_acc: 0.955431754875
2018-02-08 13:53:21,347 Epoch: 75
2018-02-08 13:53:27,659 Step: 0, train_loss: 0.00159549713135
2018-02-08 13:54:07,307 Step: 50, train_loss: 0.0505265610805
2018-02-08 13:54:46,520 Step: 100, train_loss: 0.0555508517986
2018-02-08 13:55:25,858 Step: 150, train_loss: 0.0344196868862
2018-02-08 13:56:05,114 Step: 200, train_loss: 0.0518360410642
2018-02-08 13:56:44,008 Step: 250, train_loss: 0.0382547321171
2018-02-08 13:57:23,096 Step: 300, train_loss: 0.0447174793459
2018-02-08 13:58:02,476 Step: 350, train_loss: 0.0318852139119
2018-02-08 13:58:29,801 train_loss: 0.0461380425567
2018-02-08 13:59:07,017 valid_loss: 0.165705533242, valid_acc: 0.953920220083
2018-02-08 13:59:07,033 Epoch: 76
2018-02-08 13:59:13,557 Step: 0, train_loss: 0.0995216667652
2018-02-08 13:59:52,995 Step: 50, train_loss: 0.0580907430797
2018-02-08 14:00:31,819 Step: 100, train_loss: 0.0707587015862
2018-02-08 14:01:10,826 Step: 150, train_loss: 0.0422518775618
2018-02-08 14:01:49,359 Step: 200, train_loss: 0.0531127337209
2018-02-08 14:02:28,436 Step: 250, train_loss: 0.0499338260607
2018-02-08 14:03:07,346 Step: 300, train_loss: 0.0637897060596
2018-02-08 14:03:46,758 Step: 350, train_loss: 0.0537613886909
2018-02-08 14:04:14,059 train_loss: 0.0647979763823
2018-02-08 14:04:50,775 valid_loss: 0.221865311191, valid_acc: 0.951185495119
2018-02-08 14:04:50,789 Epoch: 77
2018-02-08 14:04:57,062 Step: 0, train_loss: 0.00426917616278
2018-02-08 14:05:37,056 Step: 50, train_loss: 0.0618266489462
2018-02-08 14:06:16,257 Step: 100, train_loss: 0.0516862182229
2018-02-08 14:06:55,301 Step: 150, train_loss: 0.0282045309315
2018-02-08 14:07:34,503 Step: 200, train_loss: 0.0435813107181
2018-02-08 14:08:13,582 Step: 250, train_loss: 0.050886309304
2018-02-08 14:08:52,649 Step: 300, train_loss: 0.0493012590973
2018-02-08 14:09:31,966 Step: 350, train_loss: 0.0477218933159
2018-02-08 14:09:59,268 train_loss: 0.0474057112223
2018-02-08 14:10:36,701 valid_loss: 0.205544059027, valid_acc: 0.954109589041
2018-02-08 14:10:36,713 Epoch: 78
2018-02-08 14:10:44,420 Step: 0, train_loss: 0.110076904297
2018-02-08 14:11:24,257 Step: 50, train_loss: 0.0433227548975
2018-02-08 14:12:03,444 Step: 100, train_loss: 0.0340178120093
2018-02-08 14:12:42,644 Step: 150, train_loss: 0.0313210965553
2018-02-08 14:13:21,738 Step: 200, train_loss: 0.0365580057712
2018-02-08 14:14:00,903 Step: 250, train_loss: 0.0431154235097
2018-02-08 14:14:40,361 Step: 300, train_loss: 0.0522598881816
2018-02-08 14:15:19,575 Step: 350, train_loss: 0.0663954372797
2018-02-08 14:15:46,965 train_loss: 0.0472696778931
2018-02-08 14:16:24,378 valid_loss: 0.315009717579, valid_acc: 0.947295423024
2018-02-08 14:16:24,398 Epoch: 79
2018-02-08 14:16:31,451 Step: 0, train_loss: 0.017281267792
2018-02-08 14:17:10,682 Step: 50, train_loss: 0.0592380059656
2018-02-08 14:17:49,621 Step: 100, train_loss: 0.0386952375778
2018-02-08 14:18:28,334 Step: 150, train_loss: 0.0286889644485
2018-02-08 14:19:07,190 Step: 200, train_loss: 0.0258156075992
2018-02-08 14:19:46,107 Step: 250, train_loss: 0.041124240832
2018-02-08 14:20:25,303 Step: 300, train_loss: 0.049084106636
2018-02-08 14:21:04,731 Step: 350, train_loss: 0.0333915050927
2018-02-08 14:21:31,912 train_loss: 0.0432944842695
2018-02-08 14:22:09,242 valid_loss: 0.226623439883, valid_acc: 0.971114167813
2018-02-08 14:22:09,257 Epoch: 80
2018-02-08 14:22:16,722 Step: 0, train_loss: 0.00253507820889
2018-02-08 14:22:55,977 Step: 50, train_loss: 0.04894227318
2018-02-08 14:23:35,379 Step: 100, train_loss: 0.0261443235556
2018-02-08 14:24:14,729 Step: 150, train_loss: 0.0407609173667
2018-02-08 14:24:53,739 Step: 200, train_loss: 0.0429010905944
2018-02-08 14:25:32,762 Step: 250, train_loss: 0.0405949300725
2018-02-08 14:26:11,822 Step: 300, train_loss: 0.0389892631583
2018-02-08 14:26:50,840 Step: 350, train_loss: 0.0255581858783
2018-02-08 14:27:18,060 train_loss: 0.040843481012
2018-02-08 14:27:55,518 valid_loss: 0.155835886045, valid_acc: 0.965492957746
2018-02-08 14:27:55,534 Epoch: 81
2018-02-08 14:28:01,962 Step: 0, train_loss: 0.00623559951782
2018-02-08 14:28:41,179 Step: 50, train_loss: 0.0475154312691
2018-02-08 14:29:19,993 Step: 100, train_loss: 0.0409521552082
2018-02-08 14:29:59,140 Step: 150, train_loss: 0.0341314315848
2018-02-08 14:30:38,197 Step: 200, train_loss: 0.043990445149
2018-02-08 14:31:17,115 Step: 250, train_loss: 0.0308778859457
2018-02-08 14:31:55,975 Step: 300, train_loss: 0.0277921929432
2018-02-08 14:32:35,245 Step: 350, train_loss: 0.0372416854618
2018-02-08 14:33:02,417 train_loss: 0.042821159122
2018-02-08 14:33:39,750 valid_loss: 0.208632567455, valid_acc: 0.959644322845
2018-02-08 14:33:39,762 Epoch: 82
2018-02-08 14:33:47,475 Step: 0, train_loss: 0.103186659515
2018-02-08 14:34:27,296 Step: 50, train_loss: 0.0379298763393
2018-02-08 14:35:06,743 Step: 100, train_loss: 0.0326353871284
2018-02-08 14:35:46,216 Step: 150, train_loss: 0.0294261671405
2018-02-08 14:36:25,391 Step: 200, train_loss: 0.0340959402616
2018-02-08 14:37:04,301 Step: 250, train_loss: 0.0324129632587
2018-02-08 14:37:43,405 Step: 300, train_loss: 0.0608598356281
2018-02-08 14:38:22,865 Step: 350, train_loss: 0.0676977027429
2018-02-08 14:38:50,012 train_loss: 0.0442932743399
2018-02-08 14:39:27,751 valid_loss: 0.171146214962, valid_acc: 0.959294436906
2018-02-08 14:39:27,766 Epoch: 83
2018-02-08 14:39:34,433 Step: 0, train_loss: 0.0174224246293
2018-02-08 14:40:13,970 Step: 50, train_loss: 0.0295620319566
2018-02-08 14:40:53,197 Step: 100, train_loss: 0.0234012261895
2018-02-08 14:41:32,420 Step: 150, train_loss: 0.0413167810021
2018-02-08 14:42:11,578 Step: 200, train_loss: 0.0325612847594
2018-02-08 14:42:50,600 Step: 250, train_loss: 0.0389380366783
2018-02-08 14:43:29,746 Step: 300, train_loss: 0.0446989131544
2018-02-08 14:44:08,972 Step: 350, train_loss: 0.0297487085662
2018-02-08 14:44:35,998 train_loss: 0.0386838282937
2018-02-08 14:45:13,771 valid_loss: 0.312587619228, valid_acc: 0.964769647696
2018-02-08 14:45:13,787 Epoch: 84
2018-02-08 14:45:20,543 Step: 0, train_loss: 0.0146989822388
2018-02-08 14:46:00,270 Step: 50, train_loss: 0.0574117937894
2018-02-08 14:46:39,445 Step: 100, train_loss: 0.0378721567051
2018-02-08 14:47:18,066 Step: 150, train_loss: 0.0455556984653
2018-02-08 14:47:57,312 Step: 200, train_loss: 0.0269030161563
2018-02-08 14:48:36,278 Step: 250, train_loss: 0.0589367665024
2018-02-08 14:49:15,440 Step: 300, train_loss: 0.0440851612645
2018-02-08 14:49:54,538 Step: 350, train_loss: 0.0464184941554
2018-02-08 14:50:21,725 train_loss: 0.0488968814988
2018-02-08 14:50:58,574 valid_loss: 0.227719838991, valid_acc: 0.970097357441
2018-02-08 14:50:58,589 Epoch: 85
2018-02-08 14:51:04,723 Step: 0, train_loss: 0.00100633827969
2018-02-08 14:51:44,219 Step: 50, train_loss: 0.0473983331976
2018-02-08 15:32:35,750 Epoch: 1
2018-02-08 15:32:50,480 Step: 0, train_loss: 0.026363266632
2018-02-08 15:33:30,070 Step: 50, train_loss: 0.0636185618467
2018-02-08 15:34:09,688 Step: 100, train_loss: 0.0638888642757
2018-02-08 15:34:49,117 Step: 150, train_loss: 0.0557547520928
2018-02-08 15:35:28,560 Step: 200, train_loss: 0.0544278664235
2018-02-08 15:36:08,027 Step: 250, train_loss: 0.0701167568594
2018-02-08 15:36:47,693 Step: 300, train_loss: 0.0447460706485
2018-02-08 15:37:27,596 Step: 350, train_loss: 0.063801612251
2018-02-08 15:37:55,213 train_loss: 0.06095188157
2018-02-08 15:38:33,282 valid_loss: 0.0884956097713, valid_acc: 0.982384823848
2018-02-08 15:38:33,738 Epoch: 2
2018-02-08 15:38:40,144 Step: 0, train_loss: 0.0175320580602
2018-02-08 15:39:19,931 Step: 50, train_loss: 0.035436682757
2018-02-08 15:39:59,054 Step: 100, train_loss: 0.0526417785173
2018-02-08 15:40:38,124 Step: 150, train_loss: 0.0798670625035
2018-02-08 15:41:17,434 Step: 200, train_loss: 0.0832839739998
2018-02-08 15:41:56,533 Step: 250, train_loss: 0.0463524104864
2018-02-08 15:42:35,636 Step: 300, train_loss: 0.0694127996964
2018-02-08 15:43:14,872 Step: 350, train_loss: 0.0592584640213
2018-02-08 15:43:41,884 train_loss: 0.0661819577973
2018-02-08 15:44:19,560 valid_loss: 0.131512702017, valid_acc: 0.959366391185
2018-02-08 15:44:19,576 Epoch: 3
2018-02-08 15:44:26,868 Step: 0, train_loss: 0.0757467746735
2018-02-08 15:45:06,323 Step: 50, train_loss: 0.0535963954125
2018-02-08 15:45:45,742 Step: 100, train_loss: 0.0414421200403
2018-02-08 15:46:25,306 Step: 150, train_loss: 0.0498837623501
2018-02-08 15:47:04,854 Step: 200, train_loss: 0.0552059817058
2018-02-08 15:47:43,933 Step: 250, train_loss: 0.0722155475954
2018-02-08 15:48:23,369 Step: 300, train_loss: 0.0378112518031
2018-02-08 15:49:02,862 Step: 350, train_loss: 0.0491090444801
2018-02-08 15:49:30,059 train_loss: 0.0585993434284
2018-02-08 15:50:07,906 valid_loss: 0.237543357077, valid_acc: 0.96275862069
2018-02-08 15:50:07,919 Epoch: 4
2018-02-08 15:50:15,766 Step: 0, train_loss: 0.022278573364
2018-02-08 15:50:55,285 Step: 50, train_loss: 0.0391667378321
2018-02-08 15:51:34,915 Step: 100, train_loss: 0.0423843185441
2018-02-08 15:52:14,346 Step: 150, train_loss: 0.0541615547237
2018-02-08 15:52:53,346 Step: 200, train_loss: 0.0425755101611
2018-02-08 15:53:32,460 Step: 250, train_loss: 0.0445634027885
2018-02-08 15:54:11,931 Step: 300, train_loss: 0.0630974802171
2018-02-08 15:54:51,251 Step: 350, train_loss: 0.046324874633
2018-02-08 15:55:18,578 train_loss: 0.0504484060398
2018-02-08 15:55:56,669 valid_loss: 0.12286676612, valid_acc: 0.967123287671
2018-02-08 15:55:56,690 Epoch: 5
2018-02-08 15:56:03,253 Step: 0, train_loss: 0.0206421744078
2018-02-08 15:56:43,103 Step: 50, train_loss: 0.0508287085471
2018-02-08 15:57:22,496 Step: 100, train_loss: 0.0556103884734
2018-02-08 15:58:01,653 Step: 150, train_loss: 0.0410701357864
2018-02-08 15:58:40,975 Step: 200, train_loss: 0.0563717487326
2018-02-08 15:59:20,125 Step: 250, train_loss: 0.0633420214895
2018-02-08 15:59:59,152 Step: 300, train_loss: 0.0290996669636
2018-02-08 16:00:38,226 Step: 350, train_loss: 0.0480059875664
2018-02-08 16:01:05,552 train_loss: 0.0551945213657
2018-02-08 16:01:43,779 valid_loss: 0.17580695306, valid_acc: 0.96511627907
2018-02-08 16:01:43,793 Epoch: 6
2018-02-08 16:01:50,471 Step: 0, train_loss: 0.000594430486672
2018-02-08 16:02:30,283 Step: 50, train_loss: 0.053200452202
2018-02-08 16:03:09,752 Step: 100, train_loss: 0.0346109255674
2018-02-08 16:03:48,891 Step: 150, train_loss: 0.0526563281915
2018-02-08 16:04:27,948 Step: 200, train_loss: 0.0406481067813
2018-02-08 16:05:07,142 Step: 250, train_loss: 0.0695617897715
2018-02-08 16:05:46,177 Step: 300, train_loss: 0.0501753994811
2018-02-08 16:06:25,440 Step: 350, train_loss: 0.0604142160621
2018-02-08 16:06:52,507 train_loss: 0.0541254248939
2018-02-08 16:07:30,373 valid_loss: 0.221988284344, valid_acc: 0.958219178082
2018-02-08 16:07:30,383 Epoch: 7
2018-02-08 16:07:36,351 Step: 0, train_loss: 0.319708019495
2018-02-08 16:08:16,349 Step: 50, train_loss: 0.0387091779761
2018-02-08 16:08:55,578 Step: 100, train_loss: 0.0464247564541
2018-02-08 16:09:34,625 Step: 150, train_loss: 0.0319513308158
2018-02-08 16:10:13,778 Step: 200, train_loss: 0.0260110036272
2018-02-08 16:10:52,925 Step: 250, train_loss: 0.0424813458777
2018-02-08 16:11:32,090 Step: 300, train_loss: 0.0673319446528
2018-02-08 16:12:11,245 Step: 350, train_loss: 0.0310232837341
2018-02-08 16:12:38,227 train_loss: 0.0428802901963
2018-02-08 16:13:16,016 valid_loss: 0.354349265395, valid_acc: 0.956066945607
2018-02-08 16:13:16,031 Epoch: 8
2018-02-08 16:13:23,112 Step: 0, train_loss: 0.0251251589507
2018-02-08 16:14:02,973 Step: 50, train_loss: 0.0375347966998
2018-02-08 16:14:42,438 Step: 100, train_loss: 0.0448655370506
2018-02-08 16:15:21,889 Step: 150, train_loss: 0.0416081594652
2018-02-08 16:16:01,118 Step: 200, train_loss: 0.0504854720156
2018-02-08 16:16:40,427 Step: 250, train_loss: 0.0333727938856
2018-02-08 16:17:19,636 Step: 300, train_loss: 0.0630459308311
2018-02-08 16:17:59,352 Step: 350, train_loss: 0.0475419658329
2018-02-08 16:18:26,803 train_loss: 0.0509746767842
2018-02-08 16:19:04,431 valid_loss: 0.121899689173, valid_acc: 0.957994579946
2018-02-08 16:19:04,442 Epoch: 9
2018-02-08 16:19:10,953 Step: 0, train_loss: 0.00646289205179
2018-02-08 16:19:50,612 Step: 50, train_loss: 0.0481616338302
2018-02-08 16:20:29,994 Step: 100, train_loss: 0.0307663633779
2018-02-08 16:21:09,231 Step: 150, train_loss: 0.0405945719918
2018-02-08 16:21:48,303 Step: 200, train_loss: 0.0450684878882
2018-02-08 16:22:27,475 Step: 250, train_loss: 0.0479066534081
2018-02-08 16:23:06,971 Step: 300, train_loss: 0.0565507236915
2018-02-08 16:23:46,495 Step: 350, train_loss: 0.0361795794955
2018-02-08 16:24:13,699 train_loss: 0.0476051216675
2018-02-08 16:24:52,157 valid_loss: 0.13095747379, valid_acc: 0.965306122449
2018-02-08 16:24:52,174 Epoch: 10
2018-02-08 16:24:58,086 Step: 0, train_loss: 0.00213585956953
2018-02-08 16:25:37,972 Step: 50, train_loss: 0.0492677232728
2018-02-08 16:26:17,009 Step: 100, train_loss: 0.0505104971502
2018-02-08 16:26:56,129 Step: 150, train_loss: 0.0424374128529
2018-02-08 16:27:35,462 Step: 200, train_loss: 0.0404720834913
2018-02-08 16:28:15,076 Step: 250, train_loss: 0.0442184135318
2018-02-08 16:28:54,005 Step: 300, train_loss: 0.0399283615261
2018-02-08 16:29:33,186 Step: 350, train_loss: 0.039879010735
2018-02-08 16:30:00,688 train_loss: 0.0451231247802
2018-02-08 16:30:38,531 valid_loss: 0.20685541854, valid_acc: 0.956284153005
2018-02-08 16:30:38,545 Epoch: 11
2018-02-08 16:30:46,233 Step: 0, train_loss: 0.115756936371
2018-02-08 16:31:25,635 Step: 50, train_loss: 0.0373575447573
2018-02-08 16:32:04,648 Step: 100, train_loss: 0.0354537212302
2018-02-08 16:32:43,694 Step: 150, train_loss: 0.044874259684
2018-02-08 16:33:22,652 Step: 200, train_loss: 0.0566540752814
2018-02-08 16:34:01,854 Step: 250, train_loss: 0.0514782207765
2018-02-08 16:34:40,701 Step: 300, train_loss: 0.050604768038
2018-02-08 16:35:19,650 Step: 350, train_loss: 0.0510721699279
2018-02-08 16:35:46,907 train_loss: 0.0591312455035
2018-02-08 16:36:24,323 valid_loss: 0.186097208334, valid_acc: 0.966032608696
2018-02-08 16:36:24,336 Epoch: 12
2018-02-08 16:36:30,800 Step: 0, train_loss: 0.0501404479146
2018-02-08 16:37:10,925 Step: 50, train_loss: 0.0397024173834
2018-02-08 16:37:50,299 Step: 100, train_loss: 0.0316538681948
2018-02-08 16:38:29,789 Step: 150, train_loss: 0.0630869052632
2018-02-08 16:39:09,347 Step: 200, train_loss: 0.0561780569702
2018-02-08 16:39:48,793 Step: 250, train_loss: 0.0477890613777
2018-02-08 16:40:28,300 Step: 300, train_loss: 0.0361762083894
2018-02-08 16:41:07,799 Step: 350, train_loss: 0.039147054113
2018-02-08 16:41:34,885 train_loss: 0.0490797818806
2018-02-08 16:42:13,203 valid_loss: 0.251382180089, valid_acc: 0.95041322314
2018-02-08 16:42:13,223 Epoch: 13
2018-02-08 16:42:19,165 Step: 0, train_loss: 0.00456070899963
2018-02-08 16:44:23,877 Epoch: 1
2018-02-08 16:44:38,561 Step: 0, train_loss: 0.0562288239598
2018-02-08 16:45:18,183 Step: 50, train_loss: 0.0708027845775
2018-02-08 16:45:57,677 Step: 100, train_loss: 0.0636775310873
2018-02-08 16:46:36,999 Step: 150, train_loss: 0.0783442657045
2018-02-08 16:47:16,412 Step: 200, train_loss: 0.0550170103693
2018-02-08 16:47:55,694 Step: 250, train_loss: 0.0659203213477
2018-02-08 16:48:34,065 Step: 300, train_loss: 0.0544089281962
2018-02-08 16:49:13,269 Step: 350, train_loss: 0.0371251771261
2018-02-08 16:49:40,758 train_loss: 0.0662585709695
2018-02-08 16:50:17,439 valid_loss: 0.222398772808, valid_acc: 0.95839112344
2018-02-08 16:50:17,889 Epoch: 2
2018-02-08 16:50:23,888 Step: 0, train_loss: 0.00058913230896
2018-02-08 16:51:04,663 Step: 50, train_loss: 0.0773676196585
2018-02-08 16:51:43,980 Step: 100, train_loss: 0.0627296166989
2018-02-08 16:52:23,178 Step: 150, train_loss: 0.0608909654478
2018-02-08 16:53:02,530 Step: 200, train_loss: 0.0455448984297
2018-02-08 16:53:41,917 Step: 250, train_loss: 0.0752179165883
2018-02-08 16:54:21,500 Step: 300, train_loss: 0.0501674644928
2018-02-08 16:55:00,781 Step: 350, train_loss: 0.0563672873337
2018-02-08 16:55:27,943 train_loss: 0.062460925617
2018-02-08 16:56:04,696 valid_loss: 0.261367340517, valid_acc: 0.9470013947
2018-02-08 16:56:04,725 Epoch: 3
2018-02-08 16:56:11,542 Step: 0, train_loss: 0.0134484507143
2018-02-08 16:56:51,014 Step: 50, train_loss: 0.06423090058
2018-02-08 16:57:30,319 Step: 100, train_loss: 0.0484378099814
2018-02-08 16:58:09,688 Step: 150, train_loss: 0.0445224416512
2018-02-08 16:58:49,119 Step: 200, train_loss: 0.0346483499982
2018-02-08 16:59:28,379 Step: 250, train_loss: 0.0301034784934
2018-02-08 17:00:07,689 Step: 300, train_loss: 0.0528527283695
2018-02-08 17:00:46,985 Step: 350, train_loss: 0.0275402384216
2018-02-08 17:01:14,089 train_loss: 0.0589084333997
2018-02-08 17:01:50,781 valid_loss: 0.147759097023, valid_acc: 0.961971830986
2018-02-08 17:01:51,192 Epoch: 4
2018-02-08 17:01:58,707 Step: 0, train_loss: 0.350781172514
2018-02-08 17:02:38,556 Step: 50, train_loss: 0.0544895460046
2018-02-08 17:03:17,633 Step: 100, train_loss: 0.0526715284208
2018-02-08 17:03:56,662 Step: 150, train_loss: 0.0440731553908
2018-02-08 17:04:35,972 Step: 200, train_loss: 0.0383876736381
2018-02-08 17:05:14,953 Step: 250, train_loss: 0.063679730498
2018-02-08 17:05:54,332 Step: 300, train_loss: 0.0732447768527
2018-02-08 17:06:33,802 Step: 350, train_loss: 0.0351042219053
2018-02-08 17:07:01,326 train_loss: 0.0603860033414
2018-02-08 17:07:38,922 valid_loss: 0.204039593128, valid_acc: 0.96633941094
2018-02-08 17:07:38,936 Epoch: 5
2018-02-08 17:07:44,849 Step: 0, train_loss: 0.092027053237
2018-02-08 17:08:23,661 Step: 50, train_loss: 0.0580511076492
2018-02-08 17:09:03,068 Step: 100, train_loss: 0.0492040908855
2018-02-08 17:09:42,390 Step: 150, train_loss: 0.0409598957456
2018-02-08 17:10:21,347 Step: 200, train_loss: 0.0371453327988
2018-02-08 17:11:00,436 Step: 250, train_loss: 0.0493213041523
2018-02-08 17:11:39,786 Step: 300, train_loss: 0.0607453289255
2018-02-08 17:12:18,649 Step: 350, train_loss: 0.0546826902271
2018-02-08 17:12:45,630 train_loss: 0.0540594573421
2018-02-08 17:13:22,214 valid_loss: 0.155069826357, valid_acc: 0.964583333333
2018-02-08 17:13:22,228 Epoch: 6
2018-02-08 17:13:28,420 Step: 0, train_loss: 0.056247100234
2018-02-08 17:14:08,225 Step: 50, train_loss: 0.0412606107943
2018-02-08 17:14:47,582 Step: 100, train_loss: 0.0400175698317
2018-02-08 17:15:26,886 Step: 150, train_loss: 0.0386450960828
2018-02-08 17:16:06,346 Step: 200, train_loss: 0.0594720394316
2018-02-08 17:16:45,379 Step: 250, train_loss: 0.0547824533982
2018-02-08 17:17:24,595 Step: 300, train_loss: 0.0764590493368
2018-02-08 17:18:04,046 Step: 350, train_loss: 0.0493468270788
2018-02-08 17:18:31,384 train_loss: 0.0603192391478
2018-02-08 17:19:07,936 valid_loss: 0.272181470435, valid_acc: 0.958158995816
2018-02-08 17:19:07,950 Epoch: 7
2018-02-08 17:19:15,347 Step: 0, train_loss: 0.00680348603055
2018-02-08 17:19:54,862 Step: 50, train_loss: 0.0521639743056
2018-02-08 17:20:34,287 Step: 100, train_loss: 0.0458938391096
2018-02-08 17:21:13,579 Step: 150, train_loss: 0.0447291780775
2018-02-08 17:21:52,825 Step: 200, train_loss: 0.0518682093034
2018-02-08 17:22:32,200 Step: 250, train_loss: 0.0662210109798
2018-02-08 17:23:11,088 Step: 300, train_loss: 0.0518650226202
2018-02-08 17:23:50,240 Step: 350, train_loss: 0.0471992524725
2018-02-08 17:24:17,551 train_loss: 0.0533194331798
2018-02-08 17:24:55,101 valid_loss: 0.27289079075, valid_acc: 0.964959568733
2018-02-08 17:24:55,117 Epoch: 8
2018-02-08 17:25:02,998 Step: 0, train_loss: 0.0240552164614
2018-02-08 17:25:42,680 Step: 50, train_loss: 0.0462986939715
2018-02-08 17:26:22,055 Step: 100, train_loss: 0.077742857968
2018-02-08 17:27:01,447 Step: 150, train_loss: 0.0571277574269
2018-02-08 17:27:40,983 Step: 200, train_loss: 0.0616239728237
2018-02-08 17:28:20,119 Step: 250, train_loss: 0.0364500160399
2018-02-08 17:28:59,611 Step: 300, train_loss: 0.0341226859766
2018-02-08 17:29:39,007 Step: 350, train_loss: 0.0460623856424
2018-02-08 17:30:06,281 train_loss: 0.0516390062423
2018-02-08 17:34:46,442 Epoch: 1
2018-02-08 17:35:00,445 Step: 0, train_loss: 0.0168865527958
2018-02-08 17:35:38,668 Step: 50, train_loss: 0.0526285332977
2018-02-08 17:36:16,630 Step: 100, train_loss: 0.0726608215389
2018-02-08 17:36:54,787 Step: 150, train_loss: 0.0500691794534
2018-02-08 17:37:32,906 Step: 200, train_loss: 0.0463189110369
2018-02-08 17:38:10,854 Step: 250, train_loss: 0.0600695639965
2018-02-08 17:38:48,980 Step: 300, train_loss: 0.0790658847417
2018-02-08 17:39:27,000 Step: 350, train_loss: 0.0337088903377
2018-02-08 17:39:53,331 train_loss: 0.0622732399071
2018-02-08 17:40:30,683 valid_loss: 0.181053808054, valid_acc: 0.953188602442
2018-02-08 17:40:31,016 Epoch: 2
2018-02-08 17:40:37,228 Step: 0, train_loss: 0.145140379667
2018-02-08 17:41:15,721 Step: 50, train_loss: 0.0566950458172
2018-02-08 17:41:53,659 Step: 100, train_loss: 0.0562587263738
2018-02-08 17:42:31,765 Step: 150, train_loss: 0.0504295755798
2018-02-08 17:43:09,953 Step: 200, train_loss: 0.0510376509145
2018-02-08 17:43:47,995 Step: 250, train_loss: 0.0675800354045
2018-02-08 17:44:26,170 Step: 300, train_loss: 0.0502604704251
2018-02-08 17:45:04,315 Step: 350, train_loss: 0.048665478183
2018-02-08 17:45:30,605 train_loss: 0.0578651787675
2018-02-08 17:46:07,585 valid_loss: 0.166062974955, valid_acc: 0.955357142857
2018-02-08 17:46:07,895 Epoch: 3
2018-02-08 17:46:14,289 Step: 0, train_loss: 0.114718571305
2018-02-08 17:46:53,023 Step: 50, train_loss: 0.0539115397126
2018-02-08 17:47:30,950 Step: 100, train_loss: 0.0743417767191
2018-02-08 17:48:09,156 Step: 150, train_loss: 0.0600552672823
2018-02-08 17:48:47,359 Step: 200, train_loss: 0.0576254553584
2018-02-08 17:49:25,369 Step: 250, train_loss: 0.0404712277523
2018-02-08 17:50:03,489 Step: 300, train_loss: 0.0568190515367
2018-02-08 17:50:41,583 Step: 350, train_loss: 0.0643516959785
2018-02-08 17:51:07,780 train_loss: 0.0610787718161
2018-02-08 17:51:44,735 valid_loss: 0.0852144273923, valid_acc: 0.978968792402
2018-02-08 17:51:45,065 Epoch: 4
2018-02-08 17:51:51,682 Step: 0, train_loss: 0.0351557470858
2018-02-08 17:52:30,291 Step: 50, train_loss: 0.0878737507563
2018-02-08 17:53:08,650 Step: 100, train_loss: 0.052543743432
2018-02-08 17:53:46,996 Step: 150, train_loss: 0.0648742973269
2018-02-08 17:54:25,075 Step: 200, train_loss: 0.0416883216717
2018-02-08 17:55:03,356 Step: 250, train_loss: 0.0421302706623
2018-02-08 17:55:41,647 Step: 300, train_loss: 0.0479291590699
2018-02-08 17:56:19,692 Step: 350, train_loss: 0.0596889650007
2018-02-08 17:56:45,893 train_loss: 0.0673564377489
2018-02-08 17:57:23,145 valid_loss: 0.245811387323, valid_acc: 0.961904761905
2018-02-08 17:57:23,163 Epoch: 5
2018-02-08 17:57:29,290 Step: 0, train_loss: 0.0646184310317
2018-02-08 17:58:07,857 Step: 50, train_loss: 0.0479346093093
2018-02-08 17:58:45,699 Step: 100, train_loss: 0.0524403473211
2018-02-08 17:59:23,816 Step: 150, train_loss: 0.0690867072833
2018-02-08 18:00:01,884 Step: 200, train_loss: 0.0432369138038
2018-02-08 18:00:39,752 Step: 250, train_loss: 0.0465679859719
2018-02-08 18:01:18,014 Step: 300, train_loss: 0.0460137775214
2018-02-08 18:01:55,920 Step: 350, train_loss: 0.0386487235676
2018-02-08 18:02:21,919 train_loss: 0.0619776227801
2018-02-08 18:02:59,669 valid_loss: 0.187017929799, valid_acc: 0.959027777778
2018-02-08 18:02:59,683 Epoch: 6
2018-02-08 18:03:06,875 Step: 0, train_loss: 0.00924330297858
2018-02-08 18:03:45,314 Step: 50, train_loss: 0.0561840558157
2018-02-08 18:04:23,460 Step: 100, train_loss: 0.0345723607257
2018-02-08 18:05:01,421 Step: 150, train_loss: 0.0593390179984
2018-02-08 18:05:39,270 Step: 200, train_loss: 0.059316527124
2018-02-08 18:06:17,476 Step: 250, train_loss: 0.0464941498131
2018-02-08 18:06:55,497 Step: 300, train_loss: 0.0541127516958
2018-02-08 18:07:33,433 Step: 350, train_loss: 0.0717735893768
2018-02-08 18:07:59,521 train_loss: 0.058137006709
2018-02-08 18:08:36,119 valid_loss: 0.108894942262, valid_acc: 0.972991689751
2018-02-08 18:08:36,132 Epoch: 7
2018-02-08 18:08:41,616 Step: 0, train_loss: 0.0711751803756
2018-02-08 18:09:21,171 Step: 50, train_loss: 0.0489890122239
2018-02-08 18:09:59,238 Step: 100, train_loss: 0.0508780236926
2018-02-08 18:10:37,183 Step: 150, train_loss: 0.0574510495504
2018-02-08 18:11:15,164 Step: 200, train_loss: 0.0431063994032
2018-02-08 18:11:53,167 Step: 250, train_loss: 0.0555966260153
2018-02-08 18:12:31,144 Step: 300, train_loss: 0.06186620213
2018-02-08 18:13:09,184 Step: 350, train_loss: 0.0505543154466
2018-02-08 18:13:35,208 train_loss: 0.05943113741
2018-02-08 18:14:12,143 valid_loss: 0.171696753869, valid_acc: 0.966666666667
2018-02-08 18:14:12,156 Epoch: 8
2018-02-08 18:14:19,854 Step: 0, train_loss: 0.00680687697604
2018-02-08 18:14:58,603 Step: 50, train_loss: 0.0428005931768
2018-02-08 18:15:36,868 Step: 100, train_loss: 0.0526207763242
2018-02-08 18:16:15,117 Step: 150, train_loss: 0.0580648793944
2018-02-08 18:16:53,191 Step: 200, train_loss: 0.0556171370845
2018-02-08 18:17:30,953 Step: 250, train_loss: 0.0359692263399
2018-02-08 18:18:08,984 Step: 300, train_loss: 0.0595807706926
2018-02-08 18:18:47,145 Step: 350, train_loss: 0.0568870530254
2018-02-08 18:19:13,367 train_loss: 0.0550689819589
2018-02-08 18:19:51,570 valid_loss: 0.160359643273, valid_acc: 0.953125
2018-02-08 18:19:51,587 Epoch: 9
2018-02-08 18:19:59,152 Step: 0, train_loss: 0.00671709887683
2018-02-08 18:20:38,004 Step: 50, train_loss: 0.0397001402534
2018-02-08 18:21:16,020 Step: 100, train_loss: 0.0522770399298
2018-02-08 18:21:54,164 Step: 150, train_loss: 0.0327710856209
2018-02-08 18:22:32,005 Step: 200, train_loss: 0.0472832398536
2018-02-08 18:23:09,989 Step: 250, train_loss: 0.0574890383822
2018-02-08 18:23:48,124 Step: 300, train_loss: 0.0486200130737
2018-02-08 18:24:25,925 Step: 350, train_loss: 0.0568032251368
2018-02-08 18:24:51,984 train_loss: 0.0499936299643
2018-02-08 18:25:28,854 valid_loss: 0.108086346929, valid_acc: 0.976323119777
2018-02-08 18:25:28,865 Epoch: 10
2018-02-08 18:25:36,226 Step: 0, train_loss: 0.102002829313
2018-02-08 18:26:14,430 Step: 50, train_loss: 0.0428896482976
2018-02-08 18:26:52,792 Step: 100, train_loss: 0.0339190179307
2018-02-08 18:27:30,762 Step: 150, train_loss: 0.0599961857218
2018-02-08 18:28:08,455 Step: 200, train_loss: 0.053058263784
2018-02-08 18:28:46,302 Step: 250, train_loss: 0.0546110070113
2018-02-08 18:29:24,480 Step: 300, train_loss: 0.0496933047834
2018-02-08 18:30:02,343 Step: 350, train_loss: 0.0416742343112
2018-02-08 18:30:28,070 train_loss: 0.052486721754
2018-02-08 18:31:05,177 valid_loss: 0.089751884944, valid_acc: 0.975069252078
2018-02-08 19:16:46,279 Epoch: 1
2018-02-08 19:17:00,192 Step: 0, train_loss: 0.0252464339137
2018-02-08 19:17:38,842 Step: 50, train_loss: 0.0645595376519
2018-02-08 19:18:17,460 Step: 100, train_loss: 0.0701874723565
2018-02-08 19:18:56,245 Step: 150, train_loss: 0.0435750102252
2018-02-08 19:19:35,083 Step: 200, train_loss: 0.0392568645265
2018-02-08 19:20:13,996 Step: 250, train_loss: 0.0540521099907
2018-02-08 19:20:52,872 Step: 300, train_loss: 0.0341678132094
2018-02-08 19:21:31,612 Step: 350, train_loss: 0.0670302333764
2018-02-08 19:21:58,605 train_loss: 0.06622528637
2018-02-08 19:22:35,376 valid_loss: 0.273939471535, valid_acc: 0.96314325452
2018-02-08 19:33:15,787 Epoch: 1
2018-02-08 19:33:23,108 Step: 0, train_loss: 0.0293534472585
2018-02-08 19:34:02,439 Step: 50, train_loss: 0.0550505582721
2018-02-08 19:34:41,099 Step: 100, train_loss: 0.037839101305
2018-02-08 19:35:20,169 Step: 150, train_loss: 0.0481259056204
2018-02-08 19:35:59,002 Step: 200, train_loss: 0.0269528799743
2018-02-08 19:36:37,700 Step: 250, train_loss: 0.0450508926611
2018-02-08 19:37:16,795 Step: 300, train_loss: 0.037365114541
2018-02-08 19:37:55,617 Step: 350, train_loss: 0.0442239881237
2018-02-08 19:38:22,227 train_loss: 0.0457191242454
2018-02-08 19:38:58,395 valid_loss: 0.173170685933, valid_acc: 0.958695652174
2018-02-08 19:45:15,761 Epoch: 1
2018-02-08 19:45:23,229 Step: 0, train_loss: 0.0446697063744
2018-02-08 19:46:02,743 Step: 50, train_loss: 0.0784693812171
2018-02-08 19:46:41,693 Step: 100, train_loss: 0.0422777198651
2018-02-08 19:47:20,683 Step: 150, train_loss: 0.0647956578148
2018-02-08 19:47:59,722 Step: 200, train_loss: 0.0648395380552
2018-02-08 19:48:38,854 Step: 250, train_loss: 0.0296914608069
2018-02-08 19:49:17,872 Step: 300, train_loss: 0.0544174232386
2018-02-08 19:49:56,582 Step: 350, train_loss: 0.0697483818419
2018-02-08 19:50:23,524 train_loss: 0.0617762560338
2018-02-08 19:51:01,300 valid_loss: 0.257533377851, valid_acc: 0.957718120805
2018-02-08 19:51:01,319 Epoch: 2
2018-02-08 19:51:07,683 Step: 0, train_loss: 0.0497935861349
2018-02-08 19:51:47,197 Step: 50, train_loss: 0.0588010269008
2018-02-08 19:52:26,119 Step: 100, train_loss: 0.0576043218057
2018-02-08 19:53:04,863 Step: 150, train_loss: 0.0352438350488
2018-02-08 19:53:44,029 Step: 200, train_loss: 0.0470067817456
2018-02-08 19:54:23,158 Step: 250, train_loss: 0.0608395698501
2018-02-08 19:55:02,184 Step: 300, train_loss: 0.058869337666
2018-02-08 19:55:41,066 Step: 350, train_loss: 0.0517581770194
2018-02-08 19:56:07,730 train_loss: 0.0541969047271
2018-02-08 19:56:44,325 valid_loss: 0.216952866113, valid_acc: 0.968319559229
2018-02-08 19:56:44,342 Epoch: 3
2018-02-08 19:56:51,815 Step: 0, train_loss: 0.00211093155667
2018-02-08 19:57:31,065 Step: 50, train_loss: 0.0658628749603
2018-02-08 19:58:10,046 Step: 100, train_loss: 0.042526234542
2018-02-08 19:58:48,985 Step: 150, train_loss: 0.0438218166222
2018-02-08 19:59:28,078 Step: 200, train_loss: 0.0494881315343
2018-02-08 20:00:07,186 Step: 250, train_loss: 0.0486909606383
2018-02-08 20:00:46,127 Step: 300, train_loss: 0.049157123818
2018-02-08 20:01:24,944 Step: 350, train_loss: 0.052297457559
2018-02-08 20:01:51,814 train_loss: 0.0538171958414
2018-02-08 20:02:28,972 valid_loss: 0.12937639289, valid_acc: 0.966438356164
2018-02-08 20:02:28,995 Epoch: 4
2018-02-08 20:02:36,683 Step: 0, train_loss: 0.237361088395
2018-02-08 20:03:15,988 Step: 50, train_loss: 0.0629167302407
2018-02-08 20:03:55,133 Step: 100, train_loss: 0.0834627471806
2018-02-08 20:04:33,839 Step: 150, train_loss: 0.0415938084084
2018-02-08 20:05:12,634 Step: 200, train_loss: 0.0555816906216
2018-02-08 20:05:51,774 Step: 250, train_loss: 0.0693513715157
2018-02-08 20:06:30,499 Step: 300, train_loss: 0.0344806035788
2018-02-08 20:07:09,494 Step: 350, train_loss: 0.049737769831
2018-02-08 20:07:36,298 train_loss: 0.0613672033149
2018-02-08 20:08:13,012 valid_loss: 0.233381606561, valid_acc: 0.940054495913
2018-02-08 20:08:13,027 Epoch: 5
2018-02-08 20:08:19,579 Step: 0, train_loss: 0.0941759198904
2018-02-08 20:08:59,519 Step: 50, train_loss: 0.0460682029749
2018-02-08 20:09:38,593 Step: 100, train_loss: 0.0617253833928
2018-02-08 20:10:17,450 Step: 150, train_loss: 0.0506618202472
2018-02-08 20:10:56,524 Step: 200, train_loss: 0.0529655147414
2018-02-08 20:11:35,601 Step: 250, train_loss: 0.0473398302391
2018-02-08 20:12:14,945 Step: 300, train_loss: 0.0943185072159
2018-02-08 20:12:53,895 Step: 350, train_loss: 0.0371204657166
2018-02-08 20:13:20,883 train_loss: 0.0583824386888
2018-02-08 20:13:58,554 valid_loss: 0.21580194363, valid_acc: 0.953920220083
2018-02-08 20:13:58,570 Epoch: 6
2018-02-08 20:14:05,363 Step: 0, train_loss: 0.0484383367002
2018-02-08 20:14:44,984 Step: 50, train_loss: 0.0403318523103
2018-02-08 20:15:23,863 Step: 100, train_loss: 0.0633806913713
2018-02-08 20:16:02,833 Step: 150, train_loss: 0.0402487224271
2018-02-08 20:16:41,984 Step: 200, train_loss: 0.0445317230927
2018-02-08 20:17:20,514 Step: 250, train_loss: 0.0557341864705
2018-02-08 20:17:59,437 Step: 300, train_loss: 0.0510006077541
2018-02-08 20:18:38,378 Step: 350, train_loss: 0.0626884444931
2018-02-08 20:19:05,288 train_loss: 0.0523990324472
2018-02-08 20:19:41,761 valid_loss: 0.193348675439, valid_acc: 0.960251046025
2018-02-08 20:19:41,775 Epoch: 7
2018-02-08 20:19:48,253 Step: 0, train_loss: 0.0140809752047
2018-02-08 20:36:46,494 Epoch: 1
2018-02-08 20:37:01,117 Step: 0, train_loss: 0.241622552276
2018-02-08 20:37:40,161 Step: 50, train_loss: 0.0862768395018
2018-02-08 20:38:19,156 Step: 100, train_loss: 0.0352550423401
2018-02-08 20:38:58,001 Step: 150, train_loss: 0.0448324072629
2018-02-08 20:39:37,267 Step: 200, train_loss: 0.0434064711013
2018-02-08 20:40:16,507 Step: 250, train_loss: 0.0778075150517
2018-02-08 20:40:55,531 Step: 300, train_loss: 0.0490284431324
2018-02-08 20:41:34,529 Step: 350, train_loss: 0.0350991055666
2018-02-08 20:42:13,496 Step: 400, train_loss: 0.0389803798473
2018-02-08 20:42:13,503 train_loss: 0.051810306091
2018-02-08 20:42:50,834 valid_loss: 0.148186890459, valid_acc: 0.974530831099
2018-02-08 20:42:50,844 Epoch: 2
2018-02-08 20:42:58,543 Step: 0, train_loss: 0.042412918061
2018-02-08 20:43:38,025 Step: 50, train_loss: 0.0511174240957
2018-02-08 20:44:17,196 Step: 100, train_loss: 0.0400912842457
2018-02-08 20:44:56,191 Step: 150, train_loss: 0.0662704072252
2018-02-08 20:45:35,366 Step: 200, train_loss: 0.068745732113
2018-02-08 20:46:14,295 Step: 250, train_loss: 0.0461700825091
2018-02-08 20:46:53,304 Step: 300, train_loss: 0.0602067746126
2018-02-08 20:47:32,500 Step: 350, train_loss: 0.0469876486424
2018-02-08 20:48:11,450 Step: 400, train_loss: 0.0558752386703
2018-02-08 20:48:11,457 train_loss: 0.054403098563
2018-02-08 20:48:48,799 valid_loss: 0.107089819846, valid_acc: 0.964864864865
2018-02-08 20:48:48,811 Epoch: 3
2018-02-08 20:48:56,439 Step: 0, train_loss: 0.000207000310184
2018-02-08 20:49:35,661 Step: 50, train_loss: 0.0622639025058
2018-02-08 20:50:14,883 Step: 100, train_loss: 0.0431385770546
2018-02-08 20:50:54,124 Step: 150, train_loss: 0.0465753836793
2018-02-08 20:51:33,178 Step: 200, train_loss: 0.0485871306143
2018-02-08 20:52:12,525 Step: 250, train_loss: 0.061770187259
2018-02-08 20:52:51,540 Step: 300, train_loss: 0.0440387526929
2018-02-08 20:53:30,588 Step: 350, train_loss: 0.0601913095976
2018-02-08 20:54:09,433 Step: 400, train_loss: 0.0734312049334
2018-02-08 20:54:09,440 train_loss: 0.0548629162523
2018-02-08 20:54:47,004 valid_loss: 0.3211607963, valid_acc: 0.964572192513
2018-02-08 20:54:47,023 Epoch: 4
2018-02-08 20:54:54,193 Step: 0, train_loss: 0.00516785494983
2018-02-08 20:55:33,565 Step: 50, train_loss: 0.0414510049939
2018-02-08 20:56:13,094 Step: 100, train_loss: 0.0646891886834
2018-02-08 20:56:52,338 Step: 150, train_loss: 0.0457096787775
2018-02-08 20:57:31,394 Step: 200, train_loss: 0.0427837626899
2018-02-08 20:58:10,652 Step: 250, train_loss: 0.0582414047344
2018-02-08 20:58:49,792 Step: 300, train_loss: 0.0459975674294
2018-02-08 20:59:29,018 Step: 350, train_loss: 0.0584483049225
2018-02-08 21:00:08,092 Step: 400, train_loss: 0.0453256653599
2018-02-08 21:00:08,099 train_loss: 0.0502181963454
2018-02-08 21:00:45,580 valid_loss: 0.142979262911, valid_acc: 0.961382113821
2018-02-08 21:00:45,596 Epoch: 5
2018-02-08 21:00:52,280 Step: 0, train_loss: 0.0029069846496
2018-02-08 21:01:31,872 Step: 50, train_loss: 0.0450927992418
2018-02-08 21:02:11,122 Step: 100, train_loss: 0.0474713920895
2018-02-08 21:02:50,364 Step: 150, train_loss: 0.0500615182391
2018-02-08 21:03:29,683 Step: 200, train_loss: 0.0487681209482
2018-02-08 21:04:09,019 Step: 250, train_loss: 0.0729882931989
2018-02-08 21:04:48,234 Step: 300, train_loss: 0.0371860045614
2018-02-08 21:05:27,397 Step: 350, train_loss: 0.0535074148537
2018-02-08 21:06:06,449 Step: 400, train_loss: 0.0548953642324
2018-02-08 21:06:06,456 train_loss: 0.0511258163414
2018-02-08 21:06:43,296 valid_loss: 0.208087912461, valid_acc: 0.969008264463
2018-02-08 21:06:43,310 Epoch: 6
2018-02-08 21:06:49,639 Step: 0, train_loss: 0.0342328026891
2018-02-08 21:07:29,366 Step: 50, train_loss: 0.0650356278638
2018-02-08 21:08:08,873 Step: 100, train_loss: 0.0427597683878
2018-02-08 21:08:47,960 Step: 150, train_loss: 0.0383802361431
2018-02-08 21:09:27,061 Step: 200, train_loss: 0.0564142995822
2018-02-08 21:10:06,074 Step: 250, train_loss: 0.0412544706825
2018-02-08 21:10:44,853 Step: 300, train_loss: 0.0478600388649
2018-02-08 21:11:23,957 Step: 350, train_loss: 0.0507476339571
2018-02-08 21:12:02,657 Step: 400, train_loss: 0.0440242398804
2018-02-08 21:12:02,664 train_loss: 0.0482744353386
2018-02-08 21:12:39,728 valid_loss: 0.14162019496, valid_acc: 0.965100671141
2018-02-08 21:12:39,741 Epoch: 7
2018-02-08 21:12:46,691 Step: 0, train_loss: 0.0249274298549
2018-02-08 21:13:25,960 Step: 50, train_loss: 0.0471306691121
2018-02-08 21:14:04,908 Step: 100, train_loss: 0.0467281930795
2018-02-08 21:14:44,129 Step: 150, train_loss: 0.0559462028218
2018-02-08 21:15:23,272 Step: 200, train_loss: 0.0534780655708
2018-02-08 21:16:02,635 Step: 250, train_loss: 0.0569309899895
2018-02-08 21:16:41,389 Step: 300, train_loss: 0.0462224999
2018-02-08 21:17:20,387 Step: 350, train_loss: 0.0799481540371
2018-02-08 21:17:59,160 Step: 400, train_loss: 0.0322527552838
2018-02-08 21:17:59,167 train_loss: 0.0522613564079
2018-02-08 21:18:35,277 valid_loss: 0.0839317954782, valid_acc: 0.975675675676
2018-02-08 21:18:35,293 Epoch: 8
2018-02-08 21:18:42,287 Step: 0, train_loss: 0.0198484268039
2018-02-08 21:19:21,770 Step: 50, train_loss: 0.0532238198939
2018-02-08 21:20:01,020 Step: 100, train_loss: 0.031676011543
2018-02-08 21:20:39,988 Step: 150, train_loss: 0.0362245160469
2018-02-08 21:21:18,760 Step: 200, train_loss: 0.0463982234662
2018-02-08 21:21:57,838 Step: 250, train_loss: 0.0381590870616
2018-02-08 21:22:36,891 Step: 300, train_loss: 0.0394508677768
2018-02-08 21:23:16,170 Step: 350, train_loss: 0.0393336451804
2018-02-08 21:23:54,670 Step: 400, train_loss: 0.0363947640336
2018-02-08 21:23:54,677 train_loss: 0.0400570952043
2018-02-08 21:24:31,060 valid_loss: 0.200695079159, valid_acc: 0.975592747559
2018-02-08 21:24:31,072 Epoch: 9
2018-02-08 21:24:38,479 Step: 0, train_loss: 0.0415477752686
2018-02-08 21:26:54,360 Epoch: 1
2018-02-08 21:27:02,472 Step: 0, train_loss: 0.0918787866831
2018-02-08 21:27:42,334 Step: 50, train_loss: 0.0374308699189
2018-02-08 21:28:21,459 Step: 100, train_loss: 0.0640900449644
2018-02-08 21:29:00,669 Step: 150, train_loss: 0.0491736591342
2018-02-08 21:31:38,706 Epoch: 1
2018-02-08 21:31:47,119 Step: 0, train_loss: 0.0176224708557
2018-02-08 21:32:27,136 Step: 50, train_loss: 0.0706716242398
2018-02-08 21:33:06,591 Step: 100, train_loss: 0.0319110168878
2018-02-08 21:33:45,626 Step: 150, train_loss: 0.0423186913435
2018-02-08 21:34:24,861 Step: 200, train_loss: 0.0547658321442
2018-02-08 21:35:04,296 Step: 250, train_loss: 0.0672576120088
2018-02-08 21:35:43,746 Step: 300, train_loss: 0.0305543840464
2018-02-08 21:36:23,350 Step: 350, train_loss: 0.0357684952818
2018-02-08 21:37:02,313 Step: 400, train_loss: 0.0455144800071
2018-02-08 21:37:02,319 train_loss: 0.0472711453088
2018-02-08 21:37:39,722 valid_loss: 0.112763713071, valid_acc: 0.973648648649
2018-02-08 21:37:39,744 Epoch: 1
2018-02-08 21:37:47,179 Step: 0, train_loss: 0.0278077926487
2018-02-08 21:38:26,452 Step: 50, train_loss: 0.0452075613843
2018-02-08 21:39:05,490 Step: 100, train_loss: 0.054338614943
2018-02-08 21:39:44,521 Step: 150, train_loss: 0.0365166312354
2018-02-08 21:40:23,672 Step: 200, train_loss: 0.0391302232537
2018-02-08 21:41:02,438 Step: 250, train_loss: 0.0408454790257
2018-02-08 21:41:41,740 Step: 300, train_loss: 0.0442106221399
2018-02-08 21:42:21,077 Step: 350, train_loss: 0.0383682003489
2018-02-08 21:42:59,828 Step: 400, train_loss: 0.0518743347187
2018-02-08 21:42:59,835 train_loss: 0.0437715489904
2018-02-08 21:43:37,597 valid_loss: 0.0820695397796, valid_acc: 0.977970627503
2018-02-08 21:43:38,057 Epoch: 2
2018-02-08 21:43:44,805 Step: 0, train_loss: 0.0614056587219
2018-02-08 21:44:24,733 Step: 50, train_loss: 0.0416772280709
2018-02-08 21:45:03,965 Step: 100, train_loss: 0.0264796055283
2018-02-08 21:45:43,276 Step: 150, train_loss: 0.0618884272501
2018-02-08 21:46:22,535 Step: 200, train_loss: 0.0412138073274
2018-02-08 21:47:01,976 Step: 250, train_loss: 0.0500945558574
2018-02-08 21:47:41,112 Step: 300, train_loss: 0.0367569297756
2018-02-08 21:48:20,410 Step: 350, train_loss: 0.0396631152433
2018-02-08 21:48:59,189 Step: 400, train_loss: 0.0344039529754
2018-02-08 21:48:59,196 train_loss: 0.0415717874318
2018-02-08 21:49:37,154 valid_loss: 0.129914143285, valid_acc: 0.965100671141
2018-02-08 21:49:37,165 Epoch: 3
2018-02-08 21:49:44,906 Step: 0, train_loss: 0.0125975077972
2018-02-08 21:50:24,458 Step: 50, train_loss: 0.0480817688344
2018-02-08 21:51:03,557 Step: 100, train_loss: 0.0421995651745
2018-02-08 21:51:42,845 Step: 150, train_loss: 0.0512046621618
2018-02-08 21:52:21,875 Step: 200, train_loss: 0.0268245869549
2018-02-08 21:53:00,803 Step: 250, train_loss: 0.0419394460396
2018-02-08 21:53:40,104 Step: 300, train_loss: 0.0486680955888
2018-02-08 21:54:19,224 Step: 350, train_loss: 0.0299132180345
2018-02-08 21:54:58,075 Step: 400, train_loss: 0.052118807048
2018-02-08 21:54:58,082 train_loss: 0.0425439027422
2018-02-08 21:55:35,416 valid_loss: 0.0832140116578, valid_acc: 0.975576662144
2018-02-08 21:55:35,429 Epoch: 4
2018-02-08 21:55:43,054 Step: 0, train_loss: 0.0104961134493
2018-02-08 21:56:22,603 Step: 50, train_loss: 0.0261788607173
2018-02-08 21:57:02,109 Step: 100, train_loss: 0.0540731286086
2018-02-08 21:57:41,482 Step: 150, train_loss: 0.0421747339607
2018-02-08 21:58:20,779 Step: 200, train_loss: 0.0388324406306
2018-02-08 21:58:59,985 Step: 250, train_loss: 0.0417021044681
2018-02-08 21:59:39,046 Step: 300, train_loss: 0.0364027592377
2018-02-08 22:00:18,299 Step: 350, train_loss: 0.0307537139626
2018-02-08 22:00:57,038 Step: 400, train_loss: 0.0277131316738
2018-02-08 22:00:57,045 train_loss: 0.0371621939562
2018-02-08 22:01:34,818 valid_loss: 0.117625218646, valid_acc: 0.972899728997
2018-02-08 22:01:34,828 Epoch: 5
2018-02-08 22:01:41,609 Step: 0, train_loss: 0.175250023603
2018-02-08 22:02:22,098 Step: 50, train_loss: 0.0451308714345
2018-02-08 22:03:01,763 Step: 100, train_loss: 0.0476713091333
2018-02-08 22:03:41,367 Step: 150, train_loss: 0.0179180130432
2018-02-08 22:04:20,929 Step: 200, train_loss: 0.0582585446164
2018-02-08 22:05:00,459 Step: 250, train_loss: 0.0341803583657
2018-02-08 22:05:40,065 Step: 300, train_loss: 0.0422780300892
2018-02-08 22:06:19,286 Step: 350, train_loss: 0.0561136124004
2018-02-08 22:06:58,048 Step: 400, train_loss: 0.0248138260917
2018-02-08 22:06:58,056 train_loss: 0.0411308685345
2018-02-08 22:07:35,401 valid_loss: 0.098348672917, valid_acc: 0.969959946595
2018-02-08 22:07:35,417 Epoch: 6
2018-02-08 22:07:42,454 Step: 0, train_loss: 0.00482416152954
2018-02-08 22:08:22,396 Step: 50, train_loss: 0.0333942784322
2018-02-08 22:09:01,748 Step: 100, train_loss: 0.0430807017934
2018-02-08 22:09:40,764 Step: 150, train_loss: 0.0296288975772
2018-02-08 22:10:19,911 Step: 200, train_loss: 0.0391336936876
2018-02-08 22:10:59,144 Step: 250, train_loss: 0.037152521087
2018-02-08 22:11:38,326 Step: 300, train_loss: 0.0566522801667
2018-02-08 22:12:17,376 Step: 350, train_loss: 0.0460624486607
2018-02-08 22:12:56,184 Step: 400, train_loss: 0.0504925229863
2018-02-08 22:12:56,191 train_loss: 0.0418570857384
2018-02-08 22:13:33,939 valid_loss: 0.18334093819, valid_acc: 0.969093406593
2018-02-08 22:13:33,956 Epoch: 7
2018-02-08 22:13:41,885 Step: 0, train_loss: 0.00740136019886
2018-02-08 22:14:21,576 Step: 50, train_loss: 0.0350979516769
2018-02-08 22:15:00,855 Step: 100, train_loss: 0.0427539732918
2018-02-08 22:15:40,260 Step: 150, train_loss: 0.0430534525058
2018-02-08 22:16:19,681 Step: 200, train_loss: 0.0535346254474
2018-02-08 22:16:58,611 Step: 250, train_loss: 0.0437677747558
2018-02-08 22:17:37,900 Step: 300, train_loss: 0.0425701428641
2018-02-08 22:18:17,077 Step: 350, train_loss: 0.0392418803275
2018-02-08 22:18:56,072 Step: 400, train_loss: 0.0482148014836
2018-02-08 22:18:56,078 train_loss: 0.0434392306181
2018-02-08 22:19:34,046 valid_loss: 0.138004796258, valid_acc: 0.965659340659
2018-02-08 22:19:34,061 Epoch: 8
2018-02-08 22:19:41,278 Step: 0, train_loss: 0.429173260927
2018-02-08 22:20:21,101 Step: 50, train_loss: 0.060347473413
2018-02-08 22:21:00,493 Step: 100, train_loss: 0.0448387400509
2018-02-08 22:21:39,682 Step: 150, train_loss: 0.0448949065676
2018-02-08 22:22:18,989 Step: 200, train_loss: 0.0685184715764
2018-02-08 22:22:58,266 Step: 250, train_loss: 0.0406046619179
2018-02-08 22:23:37,654 Step: 300, train_loss: 0.0494077666578
2018-02-08 22:24:16,841 Step: 350, train_loss: 0.0373520997254
2018-02-08 22:24:55,626 Step: 400, train_loss: 0.0700696951966
2018-02-08 22:24:55,629 train_loss: 0.0529447980454
2018-02-08 22:25:33,070 valid_loss: 0.113381607831, valid_acc: 0.971606648199
2018-02-08 22:25:33,084 Epoch: 9
2018-02-08 22:25:39,653 Step: 0, train_loss: 0.00408882554621
2018-02-08 22:26:19,364 Step: 50, train_loss: 0.0406043690877
2018-02-08 22:26:58,601 Step: 100, train_loss: 0.0348711588132
2018-02-08 22:27:38,115 Step: 150, train_loss: 0.0374825441228
2018-02-08 22:28:17,481 Step: 200, train_loss: 0.0236331007537
2018-02-08 22:28:56,749 Step: 250, train_loss: 0.0312051253799
2018-02-08 22:29:36,326 Step: 300, train_loss: 0.0441644523712
2018-02-08 22:30:15,931 Step: 350, train_loss: 0.0340629973364
2018-02-08 22:30:54,981 Step: 400, train_loss: 0.06265062352
2018-02-08 22:30:54,985 train_loss: 0.038498272805
2018-02-08 22:31:33,145 valid_loss: 0.0707190001471, valid_acc: 0.977027027027
2018-02-08 22:31:33,520 Epoch: 10
2018-02-08 22:31:41,186 Step: 0, train_loss: 0.00145128043368
2018-02-08 22:32:20,943 Step: 50, train_loss: 0.0474883673055
2018-02-08 22:33:00,140 Step: 100, train_loss: 0.0443611477467
2018-02-08 22:33:39,242 Step: 150, train_loss: 0.0288991870522
2018-02-08 22:34:18,639 Step: 200, train_loss: 0.0623052404693
2018-02-08 22:34:57,826 Step: 250, train_loss: 0.0332390112756
2018-02-08 22:35:36,899 Step: 300, train_loss: 0.0375762241178
2018-02-08 22:36:15,999 Step: 350, train_loss: 0.0435176202399
2018-02-08 22:36:55,016 Step: 400, train_loss: 0.0363511664292
2018-02-08 22:36:55,020 train_loss: 0.0416168317013
2018-02-08 22:37:32,658 valid_loss: 0.321809692909, valid_acc: 0.956258411844
2018-02-08 22:46:26,830 Epoch: 1
2018-02-08 22:46:41,086 Step: 0, train_loss: 0.0133131872863
2018-02-08 22:47:19,569 Step: 50, train_loss: 0.0418347371643
2018-02-08 22:47:58,034 Step: 100, train_loss: 0.0292643586011
2018-02-08 22:48:36,625 Step: 150, train_loss: 0.0389960063202
2018-02-08 22:49:15,557 Step: 200, train_loss: 0.0434930672392
2018-02-08 22:49:54,523 Step: 250, train_loss: 0.0508610804216
2018-02-08 22:50:33,420 Step: 300, train_loss: 0.0394811853638
2018-02-08 22:51:12,300 Step: 350, train_loss: 0.042606440353
2018-02-08 22:51:50,974 Step: 400, train_loss: 0.0403372801305
2018-02-08 22:51:50,981 train_loss: 0.0407905759775
2018-02-08 22:52:27,609 valid_loss: 0.151987171543, valid_acc: 0.962466487936
2018-02-08 22:52:27,629 Epoch: 1
2018-02-08 22:52:35,459 Step: 0, train_loss: 0.0811273530126
2018-02-08 22:53:14,583 Step: 50, train_loss: 0.0429838733189
2018-02-08 22:53:53,469 Step: 100, train_loss: 0.0440733458183
2018-02-08 22:54:32,456 Step: 150, train_loss: 0.0501740705021
2018-02-08 22:55:11,275 Step: 200, train_loss: 0.0453472169291
2018-02-08 22:55:50,270 Step: 250, train_loss: 0.0329068872303
2018-02-08 22:56:29,092 Step: 300, train_loss: 0.0421424988611
2018-02-08 22:57:07,827 Step: 350, train_loss: 0.0420074904105
2018-02-08 22:57:46,589 Step: 400, train_loss: 0.0478239693493
2018-02-08 22:57:46,595 train_loss: 0.0435264213815
2018-02-08 22:58:23,594 valid_loss: 0.215178594165, valid_acc: 0.97654155496
2018-02-08 22:58:23,614 Epoch: 1
2018-02-08 22:58:31,178 Step: 0, train_loss: 0.001477453392
2018-02-08 22:59:10,397 Step: 50, train_loss: 0.0523729320869
2018-02-08 22:59:49,623 Step: 100, train_loss: 0.0403092283583
2018-02-08 23:00:28,804 Step: 150, train_loss: 0.0397164795019
2018-02-08 23:01:08,058 Step: 200, train_loss: 0.0310964949493
2018-02-08 23:01:47,293 Step: 250, train_loss: 0.0513248964818
2018-02-08 23:02:26,556 Step: 300, train_loss: 0.0388314055308
2018-02-08 23:03:05,702 Step: 350, train_loss: 0.0362931011192
2018-02-08 23:03:44,725 Step: 400, train_loss: 0.0343153010489
2018-02-08 23:03:44,729 train_loss: 0.0404350858036
2018-02-08 23:04:21,361 valid_loss: 0.263503942028, valid_acc: 0.977611940299
2018-02-08 23:04:21,379 Epoch: 2
2018-02-08 23:04:28,840 Step: 0, train_loss: 0.000698937335983
2018-02-08 23:05:08,273 Step: 50, train_loss: 0.0368147313086
2018-02-08 23:05:47,317 Step: 100, train_loss: 0.0281972941583
2018-02-08 23:06:26,718 Step: 150, train_loss: 0.0514019674691
2018-02-08 23:07:05,678 Step: 200, train_loss: 0.0842614269134
2018-02-08 23:07:45,023 Step: 250, train_loss: 0.0423767742059
2018-02-08 23:08:24,230 Step: 300, train_loss: 0.0460626210805
2018-02-08 23:09:03,421 Step: 350, train_loss: 0.0496793119177
2018-02-08 23:09:42,283 Step: 400, train_loss: 0.0543414702692
2018-02-08 23:09:42,289 train_loss: 0.0490211441483
2018-02-08 23:10:18,639 valid_loss: 0.102774339393, valid_acc: 0.973324213406
